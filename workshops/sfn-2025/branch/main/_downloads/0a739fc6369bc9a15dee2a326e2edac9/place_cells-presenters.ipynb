{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a20a897",
   "metadata": {
    "tags": [
     "hide-input",
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"plotting functions contained within `_documentation_utils` are intended for nemos's documentation.\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Ignoring cached namespace 'core'\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"invalid value encountered in div \"\n",
    "    ),\n",
    "    category=RuntimeWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ac4d7",
   "metadata": {},
   "source": [
    ":::{admonition} Download\n",
    ":class: important render-all\n",
    "\n",
    "This notebook can be downloaded as **{nb-download}`place_cells-presenters.ipynb`**. See the button at the top right to download as markdown or pdf.\n",
    "\n",
    ":::\n",
    "\n",
    "# Fit an Encoding Model\n",
    "This notebook has had all its explanatory text removed and has not been run.\n",
    " It is intended to be downloaded and run locally (or on the provided binder)\n",
    " while listening to the presenter's explanation. In order to see the fully\n",
    " rendered of this notebook, go [here](../../full/day2/place_cells.md)\n",
    "\n",
    "\n",
    "\n",
    "In this short group project we will keep working on the hippocampal place field recordings. In particular, we will learn how to model neural responses to multiple predictors: position and speed. \n",
    "\n",
    "\n",
    "\n",
    "## >>>> Should Be Cropped When Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16901008",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "\n",
    "import nemos as nmo\n",
    "\n",
    "# some helper plotting functions\n",
    "from nemos import _documentation_utils as doc_plots\n",
    "import workshop_utils\n",
    "\n",
    "# configure plots some\n",
    "plt.style.use(nmo.styles.plot_style)\n",
    "\n",
    "import workshop_utils\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "\n",
    "# shut down jax to numpy conversion warning\n",
    "nap.nap_config.suppress_conversion_warnings = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f31d2",
   "metadata": {},
   "source": [
    "## Pynapple\n",
    "\n",
    "\n",
    "- Load the data using pynapple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267d5fb",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "path = workshop_utils.fetch_data(\"Achilles_10252013_EEG.nwb\")\n",
    "data = nap.load_file(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21560126",
   "metadata": {},
   "source": [
    "- Extract the spike times and mouse position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a892a",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = data[\"units\"]\n",
    "position = data[\"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17baacf1",
   "metadata": {},
   "source": [
    "- Restrict data to when animal was traversing the linear track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e99dd",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "position = position.restrict(data[\"forward_ep\"])\n",
    "spikes = spikes.restrict(data[\"forward_ep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724e8d0",
   "metadata": {},
   "source": [
    "- Restrict neurons to only excitatory neurons, discarding neurons with a low-firing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b23766",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = spikes.getby_category(\"cell_type\")[\"pE\"]\n",
    "spikes = spikes.getby_threshold(\"rate\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a005b71",
   "metadata": {},
   "source": [
    "### Place fields\n",
    "\n",
    "\n",
    "\n",
    "- Visualize the *place fields*: neuronal firing rate as a function of position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c7301",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "place_fields = nap.compute_tuning_curves(spikes, position, bins=50, epochs=position.time_support, feature_names=[\"distance\"])\n",
    "workshop_utils.plot_place_fields(place_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7796a",
   "metadata": {},
   "source": [
    "- For speed, we're only going to investigate the three neurons highlighted above.\n",
    "- Bin spikes to counts at 100 Hz.\n",
    "- Interpolate position to match spike resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18d677",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "neurons = [82, 92, 220]\n",
    "place_fields = place_fields.sel(unit=neurons)\n",
    "spikes = spikes[neurons]\n",
    "bin_size = .01\n",
    "count = spikes.count(bin_size, ep=position.time_support)\n",
    "position = position.interpolate(count, ep=count.time_support)\n",
    "print(count.shape)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adfaaf",
   "metadata": {},
   "source": [
    "### Extract Speed per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf8a0e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "speed = []\n",
    "# Analyzing each epoch separately avoids edge effects.\n",
    "for s, e in position.time_support.values: \n",
    "    pos_ep = position.get(s, e)\n",
    "    # Absolute difference of two consecutive points\n",
    "    speed_ep = np.abs(np.diff(pos_ep)) \n",
    "    # Padding the edge so that the size is the same as the position/spike counts\n",
    "    speed_ep = np.pad(speed_ep, [0, 1], mode=\"edge\") \n",
    "    # Converting to cm/s \n",
    "    speed_ep = speed_ep * position.rate\n",
    "    speed.append(speed_ep)\n",
    "\n",
    "speed = nap.Tsd(t=position.t, d=np.hstack(speed), time_support=position.time_support)\n",
    "print(speed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc490bf",
   "metadata": {},
   "source": [
    "## <<<< End of Part to Be Cropped\n",
    "\n",
    "### Position and Speed modulation\n",
    "\n",
    "\n",
    "\n",
    "- Compute the tuning curve with pynapple's [`compute_tuning_curves`](https://pynapple.org/generated/pynapple.process.tuning_curves.html#pynapple.process.tuning_curves.compute_tuning_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92725be0",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "tc_speed = nap.compute_tuning_curves(spikes, speed, bins=20, epochs=speed.time_support, feature_names=[\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d720ef8",
   "metadata": {},
   "source": [
    "- Visualize the position and speed tuning for these neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16115d6",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = workshop_utils.plot_position_speed(position, speed, place_fields, tc_speed, neurons);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783100dc",
   "metadata": {},
   "source": [
    "These neurons all show both position and speed tuning, and we see that the animal's speed and position are highly correlated. GLMs can help us model responses to multiple, potentially correlated predictors. \n",
    "\n",
    "The goal of this project is to fit a PopulationGLM including both position and speed as predictors, and check if this model  accurately captures the tuning curves of the neurons.\n",
    "\n",
    "\n",
    "\n",
    "### Basis evaluation\n",
    "\n",
    "\n",
    "\n",
    "- why basis?\n",
    "   - without basis:\n",
    "     - either the GLM says that firing rate increases exponentially as position or speed increases, which is fairly nonsensical,\n",
    "     - or we have to fit the weight separately for each position or speed, which is really high-dim\n",
    "   - so, basis allows us to reduce dimensionality, capture non-linear modulation of firing rate (in this case, tuning)\n",
    "- why eval?\n",
    "    - basis objects have two modes:\n",
    "    - conv, like we've seen, for capturing time-dependent effects\n",
    "    - eval, for capturing non-linear modulation / tuning\n",
    "- why MSpline?\n",
    "    - when deciding on eval basis, look at the tuning you want to capture, compare to the kernels: you want your tuning to be capturable by a linear combination of these\n",
    "    - in cases like this, many possible basis objects we could use here and what I'll show you in a bit will allow you to determine which to use in principled manner\n",
    "    - MSpline, BSpline, RaisedCosineLinear : all would let you capture this\n",
    "    - weird choices:\n",
    "        - cyclic bspline, except maybe for position? if end and start are the same\n",
    "        - RaisedCosineLog (don't want the stretching)\n",
    "        - orthogonalized exponential (specialized for...)\n",
    "        - identity / history (too basic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Create a separate basis object for each model input (speed and position).\n",
    "- Provide a label for each basis (\"position\" and \"speed\").\n",
    "- Visualize the basis objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1b7e9",
   "metadata": {
    "tag": [
     "render-presenter"
    ]
   },
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\")\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15, label=\"speed\")\n",
    "workshop_utils.plot_pos_speed_bases(position_basis, speed_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95812d0e",
   "metadata": {},
   "source": [
    "- For users new to NeMoS: call `compute_fatures` for both position and speed basis, and concatenate the result to form a single design matrix.\n",
    "- Alternatively, for people familiar with NeMoS, add the basis together, and call `compute_fatures` on the newly created additive basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe72b7f",
   "metadata": {
    "tag": [
     "render-presenter"
    ]
   },
   "outputs": [],
   "source": [
    "# equivalent to calling nmo.basis.AdditiveBasis(position_basis, speed_basis)\n",
    "basis = position_basis + speed_basis\n",
    "basis.compute_features(position, speed)\n",
    "X = basis.compute_features(position, speed)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc59453",
   "metadata": {},
   "source": [
    "- Notice that, since we passed the basis pynapple objects, we got one back, preserving the time stamps.\n",
    "- `X` has the same number of time points as our input position and speed, but 25 columns. The columns come from  `n_basis_funcs` from each basis (10 for position, 15 for speed).\n",
    "\n",
    "\n",
    "\n",
    "### Model learning\n",
    "\n",
    "\n",
    "\n",
    "- Initialize `PopulationGLM`\n",
    "- Use the \"LBFGS\" solver and pass `{\"tol\": 1e-12}` to `solver_kwargs`.\n",
    "- Fit the data, passing the design matrix and spike counts to the glm object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392018a4",
   "metadata": {
    "tag": [
     "render-presenter"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "glm = nmo.glm.PopulationGLM(\n",
    "    solver_kwargs={\"tol\": 1e-12},\n",
    "    solver_name=\"LBFGS\",\n",
    ")\n",
    "\n",
    "glm.fit(X, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db7fc4",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "\n",
    "\n",
    "- Use `predict` to check whether our GLM has captured each neuron's speed and position tuning.\n",
    "- Remember to convert the predicted firing rate to spikes per second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a6033",
   "metadata": {
    "tag": [
     "render-presenter"
    ]
   },
   "outputs": [],
   "source": [
    "# predict the model's firing rate\n",
    "predicted_rate = glm.predict(X) / bin_size\n",
    "\n",
    "# same shape as the counts we were trying to predict\n",
    "print(predicted_rate.shape, count.shape)\n",
    "\n",
    "# compute the position and speed tuning curves using the predicted firing rate.\n",
    "glm_tuning_pos = nap.compute_tuning_curves(predicted_rate, position, bins=50, epochs=position.time_support, feature_names=[\"position\"])\n",
    "glm_tuning_speed = nap.compute_tuning_curves(predicted_rate, speed, bins=30, epochs=speed.time_support, feature_names=[\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a93cf",
   "metadata": {},
   "source": [
    "- Compare model and data tuning curves together. The model did a pretty good job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23034a91",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "workshop_utils.plot_position_speed_tuning(place_fields, tc_speed, glm_tuning_pos, glm_tuning_speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a6d233",
   "metadata": {},
   "source": [
    "We can see that this model does a good job capturing both the position and the speed. In the rest of this notebook, we're going to investigate all the scientific decisions that we swept under the rug: should we regularize the model? what basis should we use? do we need both inputs?\n",
    "\n",
    "\n",
    "## Extra Exercise\n",
    "\n",
    "\n",
    "\n",
    "If you breezed through this exercise and you feel like working a bit more, here is some suggestions:\n",
    "\n",
    "- Try to fit and compare the results we just obtained with different models: \n",
    "  - A model with position as the only predictor.\n",
    "  - A model with speed as the only predictor.\n",
    "- Introduce L1 (Lasso) regularization and fit models with increasingly large penalty strengths ($\\lambda$). Plot the regularization path showing how each coefficient changes with $\\lambda$. Identify which coefficients remain non-zero longest as $\\lambda$ increases - these correspond to the most informative predictors.\n",
    "\n",
    "\n",
    "To make your lives easier, you can use the helper function  below to visualize model predictions.\n",
    "\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    "\n",
    "The data in this tutorial comes from [Grosmark, Andres D., and György Buzsáki. \"Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences.\" Science 351.6280 (2016): 1440-1443](https://www.science.org/doi/full/10.1126/science.aad1935)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.18.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   42,
   65,
   89,
   97,
   103,
   109,
   114,
   122,
   127,
   135,
   140,
   149,
   154,
   164,
   175,
   179,
   196,
   208,
   212,
   220,
   224,
   265,
   271,
   279,
   287,
   306,
   316,
   327,
   339,
   347,
   351
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}