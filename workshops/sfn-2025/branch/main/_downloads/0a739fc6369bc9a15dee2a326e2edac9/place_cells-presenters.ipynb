{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d411660",
   "metadata": {
    "tags": [
     "hide-input",
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"plotting functions contained within `_documentation_utils` are intended for nemos's documentation.\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Ignoring cached namespace 'core'\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"invalid value encountered in div \"\n",
    "    ),\n",
    "    category=RuntimeWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9845f4",
   "metadata": {},
   "source": [
    ":::{admonition} Download\n",
    ":class: important render-all\n",
    "\n",
    "This notebook can be downloaded as **{nb-download}`place_cells-presenters.ipynb`**. See the button at the top right to download as markdown or pdf.\n",
    "\n",
    ":::\n",
    "\n",
    "# Model selection\n",
    "This notebook has had all its explanatory text removed and has not been run.\n",
    " It is intended to be downloaded and run locally (or on the provided binder)\n",
    " while listening to the presenter's explanation. In order to see the fully\n",
    " rendered of this notebook, go [here](../../full/day2/place_cells.md)\n",
    "\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Review how to use pynapple to analyze neuronal tuning\n",
    "- Learn how to combine NeMoS basis objects for modeling multiple predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67684be2",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "\n",
    "import nemos as nmo\n",
    "\n",
    "# some helper plotting functions\n",
    "from nemos import _documentation_utils as doc_plots\n",
    "import workshop_utils\n",
    "\n",
    "# configure plots some\n",
    "plt.style.use(nmo.styles.plot_style)\n",
    "\n",
    "import workshop_utils\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "\n",
    "# shut down jax to numpy conversion warning\n",
    "nap.nap_config.suppress_conversion_warnings = True\n",
    "\n",
    "# during development, set this to a lower number so everything runs faster. \n",
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfcf454",
   "metadata": {},
   "source": [
    "## Pynapple\n",
    "\n",
    "\n",
    "- Load the data using pynapple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05213b",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "path = workshop_utils.fetch_data(\"Achilles_10252013_EEG.nwb\")\n",
    "data = nap.load_file(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc66b2d",
   "metadata": {},
   "source": [
    "- Extract the spike times and mouse position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90bbcf4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = data[\"units\"]\n",
    "position = data[\"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e2f77",
   "metadata": {},
   "source": [
    "- Restrict data to when animal was traversing the linear track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ba32e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "position = position.restrict(data[\"forward_ep\"])\n",
    "spikes = spikes.restrict(data[\"forward_ep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca819319",
   "metadata": {},
   "source": [
    "- Restrict neurons to only excitatory neurons, discarding neurons with a low-firing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf097c",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = spikes.getby_category(\"cell_type\")[\"pE\"]\n",
    "spikes = spikes.getby_threshold(\"rate\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abe5ce",
   "metadata": {},
   "source": [
    "### Place fields\n",
    "\n",
    "\n",
    "\n",
    "- Visualize the *place fields*: neuronal firing rate as a function of position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694557c5",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "place_fields = nap.compute_tuning_curves(spikes, position, bins=50, epochs=position.time_support, feature_names=[\"distance\"])\n",
    "workshop_utils.plot_place_fields(place_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffa57e",
   "metadata": {},
   "source": [
    "- For speed, we're only going to investigate the three neurons highlighted above.\n",
    "- Bin spikes to counts at 100 Hz.\n",
    "- Interpolate position to match spike resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262e397",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "neurons = [82, 92, 220]\n",
    "place_fields = place_fields.sel(unit=neurons)\n",
    "spikes = spikes[neurons]\n",
    "bin_size = .01\n",
    "count = spikes.count(bin_size, ep=position.time_support)\n",
    "position = position.interpolate(count, ep=count.time_support)\n",
    "print(count.shape)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1b136",
   "metadata": {},
   "source": [
    "### Speed modulation\n",
    "\n",
    "\n",
    "\n",
    "- Compute animal's speed for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01c2b2",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "speed = []\n",
    "# Analyzing each epoch separately avoids edge effects.\n",
    "for s, e in position.time_support.values: \n",
    "    pos_ep = position.get(s, e)\n",
    "    # Absolute difference of two consecutive points\n",
    "    speed_ep = np.abs(np.diff(pos_ep)) \n",
    "    # Padding the edge so that the size is the same as the position/spike counts\n",
    "    speed_ep = np.pad(speed_ep, [0, 1], mode=\"edge\") \n",
    "    # Converting to cm/s \n",
    "    speed_ep = speed_ep * position.rate\n",
    "    speed.append(speed_ep)\n",
    "\n",
    "speed = nap.Tsd(t=position.t, d=np.hstack(speed), time_support=position.time_support)\n",
    "print(speed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3edd42",
   "metadata": {},
   "source": [
    "- Compute the tuning curve with pynapple's [`compute_tuning_curves`](https://pynapple.org/generated/pynapple.process.tuning_curves.html#pynapple.process.tuning_curves.compute_tuning_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b28229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_speed = nap.compute_tuning_curves(spikes, speed, bins=20, epochs=speed.time_support, feature_names=[\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ea6e5",
   "metadata": {},
   "source": [
    "- Visualize the position and speed tuning for these neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf1657",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = workshop_utils.plot_position_speed(position, speed, place_fields, tc_speed, neurons);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff34035",
   "metadata": {},
   "source": [
    "These neurons all show both position and speed tuning, and we see that the animal's speed and position are highly correlated. We're going to build a GLM to predict neuronal firing rate -- which variable should we use? Is the speed tuning just epiphenomenal?\n",
    "\n",
    "\n",
    "\n",
    "## NeMoS\n",
    "\n",
    "### Basis evaluation\n",
    "\n",
    "\n",
    "\n",
    "- why basis?\n",
    "   - without basis:\n",
    "     - either the GLM says that firing rate increases exponentially as position or speed increases, which is fairly nonsensical,\n",
    "     - or we have to fit the weight separately for each position or speed, which is really high-dim\n",
    "   - so, basis allows us to reduce dimensionality, capture non-linear modulation of firing rate (in this case, tuning)\n",
    "- why eval?\n",
    "    - basis objects have two modes:\n",
    "    - conv, like we've seen, for capturing time-dependent effects\n",
    "    - eval, for capturing non-linear modulation / tuning\n",
    "- why MSpline?\n",
    "    - when deciding on eval basis, look at the tuning you want to capture, compare to the kernels: you want your tuning to be capturable by a linear combination of these\n",
    "    - in cases like this, many possible basis objects we could use here and what I'll show you in a bit will allow you to determine which to use in principled manner\n",
    "    - MSpline, BSpline, RaisedCosineLinear : all would let you capture this\n",
    "    - weird choices:\n",
    "        - cyclic bspline, except maybe for position? if end and start are the same\n",
    "        - RaisedCosineLog (don't want the stretching)\n",
    "        - orthogonalized exponential (specialized for...)\n",
    "        - identity / history (too basic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Create a separate basis object for each model input.\n",
    "- Visualize the basis objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70142fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10)\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15)\n",
    "workshop_utils.plot_pos_speed_bases(position_basis, speed_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eec7be",
   "metadata": {},
   "source": [
    "- Combine the two basis objects into a single \"additive basis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to calling nmo.basis.AdditiveBasis(position_basis, speed_basis)\n",
    "basis = position_basis + speed_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b2734",
   "metadata": {},
   "source": [
    "- Create the design matrix!\n",
    "- Notice that, since we passed the basis pynapple objects, we got one back, preserving the time stamps.\n",
    "- `X` has the same number of time points as our input position and speed, but 25 columns. The columns come from  `n_basis_funcs` from each basis (10 for position, 15 for speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c57cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = basis.compute_features(position, speed)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be0d28",
   "metadata": {},
   "source": [
    "### Model learning\n",
    "\n",
    "\n",
    "\n",
    "- Initialize `PopulationGLM`\n",
    "- Use the \"LBFGS\" solver and pass `{\"tol\": 1e-12}` to `solver_kwargs`.\n",
    "- Fit the data, passing the design matrix and spike counts to the glm object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = nmo.glm.PopulationGLM(\n",
    "    solver_kwargs={\"tol\": 1e-12},\n",
    "    solver_name=\"LBFGS\",\n",
    ")\n",
    "\n",
    "glm.fit(X, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e437917",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "\n",
    "\n",
    "- Use `predict` to check whether our GLM has captured each neuron's speed and position tuning.\n",
    "- Remember to convert the predicted firing rate to spikes per second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e56ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model's firing rate\n",
    "predicted_rate = glm.predict(X) / bin_size\n",
    "\n",
    "# same shape as the counts we were trying to predict\n",
    "print(predicted_rate.shape, count.shape)\n",
    "\n",
    "# compute the position and speed tuning curves using the predicted firing rate.\n",
    "glm_pos = nap.compute_tuning_curves(predicted_rate, position, bins=50, epochs=position.time_support, feature_names=[\"position\"])\n",
    "glm_speed = nap.compute_tuning_curves(predicted_rate, speed, bins=30, epochs=speed.time_support, feature_names=[\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff090d",
   "metadata": {},
   "source": [
    "- Compare model and data tuning curves together. The model did a pretty good job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69d89b",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "workshop_utils.plot_position_speed_tuning(place_fields, tc_speed, glm_pos, glm_speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25620bc",
   "metadata": {},
   "source": [
    "We can see that this model does a good job capturing both the position and the speed. In the rest of this notebook, we're going to investigate all the scientific decisions that we swept under the rug: should we regularize the model? what basis should we use? do we need both inputs?\n",
    "\n",
    "To make our lives easier, let's create a helper function that wraps the above\n",
    "lines, because we're going to be visualizing our model predictions a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ae96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_predictions(glm, X):\n",
    "    # predict the model's firing rate\n",
    "    predicted_rate = glm.predict(X) / bin_size\n",
    "\n",
    "    # compute the position and speed tuning curves using the predicted firing rate.\n",
    "    glm_pos = nap.compute_tuning_curves(predicted_rate, position, bins=50, epochs=position.time_support, feature_names=[\"position\"])\n",
    "    glm_speed = nap.compute_tuning_curves(predicted_rate, speed, bins=30, epochs=position.time_support, feature_names=[\"speed\"])\n",
    "\n",
    "    workshop_utils.plot_position_speed_tuning(place_fields, tc_speed, glm_pos, glm_speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a87fe",
   "metadata": {},
   "source": [
    "In our previous analysis of the place field hyppocampal dataset we compared multiple encoding models and tried to figure out which predictor (position, speed or phase) had more explanatory power. In this notebook we will keep going on that effort and learn more principled (and convenient) approaches to model comparison combining NeMoS and scikit-learn.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn how to use NeMoS objects with [scikit-learn](https://scikit-learn.org/) for cross-validation\n",
    "- Learn how to use NeMoS objects with scikit-learn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- Learn how to use cross-validation to perform model and feature selection\n",
    "- \n",
    "\n",
    "\n",
    "## Scikit-learn\n",
    "\n",
    "### How to know when to regularize?\n",
    "\n",
    "\n",
    "\n",
    "- How do we decide when to use regularization?\n",
    "- Cross-validation allows you to fairly compare different models on the same dataset.\n",
    "- NeMoS makes use of [scikit-learn](https://scikit-learn.org/), the standard machine learning library in python.\n",
    "- Define [parameter grid](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) to search over.\n",
    "- Anything not specified in grid will be kept constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Ridge GLM\n",
    "glm = nmo.glm.PopulationGLM(\n",
    "    regularizer=\"Ridge\",\n",
    "    solver_kwargs={\"tol\": 1e-12},\n",
    "    solver_name=\"LBFGS\",\n",
    ")\n",
    "param_grid = {\n",
    "    \"regularizer_strength\": [0.0001, 1.],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bbabe1",
   "metadata": {},
   "source": [
    "- Initialize scikit-learn's [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.GridSearchCV(glm, param_grid, cv=cv_folds)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d22c5",
   "metadata": {},
   "source": [
    "- We interact with this in a very similar way to the glm object.\n",
    "- In particular, call `fit` with same arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e82fbf",
   "metadata": {},
   "source": [
    "- We got a warning because we didn't specify the regularizer strength, so we just fell back on default value.\n",
    "- Let's investigate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b401a3a",
   "metadata": {},
   "source": [
    "### Select basis\n",
    "\n",
    "\n",
    "\n",
    "- You can (and should) do something similar to determine how many basis functions you need for each input.\n",
    "- NeMoS basis objects are not scikit-learn-compatible right out of the box.\n",
    "- But we have provided a simple method to make them so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\").to_transformer()\n",
    "# or equivalently:\n",
    "position_basis = nmo.basis.TransformerBasis(nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\"))\n",
    "position_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da5656",
   "metadata": {},
   "source": [
    "- This gives the basis object the `transform` method, which is equivalent to `compute_features`.\n",
    "- However, transformers have some limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148f1ef",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "position_basis.transform(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd493daa",
   "metadata": {},
   "source": [
    "- Transformers only accept 2d inputs, whereas nemos basis objects can accept inputs of any dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f14d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis.transform(position[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d724d",
   "metadata": {},
   "source": [
    "- If the basis is composite (for example, the addition of two 1D bases), the transformer will expect a shape of `(n_sampels, 1)` each 1D component. If that's not the case, you need to call `set_input_shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff63279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a composite basis\n",
    "basis_2d = nmo.basis.MSplineEval(5) +  nmo.basis.MSplineEval(5)\n",
    "basis_2d = basis_2d.to_transformer()\n",
    "\n",
    "# this will work: 1 input per component\n",
    "x, y = np.random.randn(10, 1), np.random.randn(10, 1)\n",
    "X = np.concatenate([x, y], axis=1)\n",
    "result = basis_2d.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe23cb4",
   "metadata": {},
   "source": [
    "- Then you can call transform on the 2d input as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e085b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 2 input for the first component and 3 for the second.\n",
    "x, y = np.random.randn(10, 2), np.random.randn(10, 3)\n",
    "X = np.concatenate([x, y], axis=1)\n",
    "try:\n",
    "    basis_2d.transform(X)\n",
    "except Exception as e:\n",
    "    print(\"Exception Raised:\")\n",
    "    print(repr(e))\n",
    "\n",
    "# Set the expected input shape instead.\n",
    "\n",
    "# array\n",
    "res1 = basis_2d.set_input_shape(x, y).transform(X)\n",
    "# int\n",
    "res2 = basis_2d.set_input_shape(2, 3).transform(X)\n",
    "# tuple\n",
    "res3 = basis_2d.set_input_shape((2,), (3,)).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77d3a1",
   "metadata": {},
   "source": [
    "- You can, equivalently, call `compute_features` *before* turning the basis into a transformer. Then we cache the shape for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\")\n",
    "position_basis.compute_features(position)\n",
    "position_basis = position_basis.to_transformer()\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15, label=\"speed\").to_transformer().set_input_shape(1)\n",
    "basis = position_basis + speed_basis\n",
    "basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c112e",
   "metadata": {},
   "source": [
    "- Create a single TsdFrame to hold all our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00e2f1",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "transformer_input = nap.TsdFrame(\n",
    "    t=position.t,\n",
    "    d=np.stack([position, speed], 1),\n",
    "    time_support=position.time_support,\n",
    "    columns=[\"position\", \"speed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278be4df",
   "metadata": {},
   "source": [
    "- Pass this input to our transformed additive basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis.transform(transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6f2d3",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "\n",
    "\n",
    "- If we want to cross-validate over the basis, we need more one more step: combining the basis and the GLM into a single scikit-learn estimator.\n",
    "- [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25eb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the reg strength to the optimal\n",
    "glm = nmo.glm.PopulationGLM(solver_name=\"LBFGS\", solver_kwargs={\"tol\": 10**-12})\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"basis\", basis),\n",
    "    (\"glm\", glm)\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f081f71",
   "metadata": {},
   "source": [
    "- Pipeline runs `basis.transform`, then passes that output to `glm`, so we can do everything in a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53249db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49652aee",
   "metadata": {},
   "source": [
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94daa4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model_predictions(pipe, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5c5de",
   "metadata": {},
   "source": [
    "### Cross-validating on the basis\n",
    "\n",
    "\n",
    "\n",
    "Now that we have our pipeline estimator, we can cross-validate on any of its parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ddf3d",
   "metadata": {},
   "source": [
    "Let's cross-validate on:\n",
    "- The number of the basis functions of the position basis\n",
    "- The functional form of the basis for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe[\"basis\"][\"position\"].n_basis_funcs)\n",
    "print(pipe[\"basis\"][\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c22326",
   "metadata": {},
   "source": [
    "- Construct `param_grid`, using `__` to stand in for `.`\n",
    "- In sklearn pipelines, we access nested parameters using double underscores:\n",
    "  - `pipe[\"basis\"][\"position\"].n_basis_funcs` ← normal Python syntax\n",
    "  - `\"basis__position__n_basis_funcs\"` ← sklearn parameter grid syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"basis__position__n_basis_funcs\": [5, 10, 20],\n",
    "    \"basis__speed\": [nmo.basis.MSplineEval(15).set_input_shape(1),\n",
    "                      nmo.basis.BSplineEval(15).set_input_shape(1),\n",
    "                      nmo.basis.RaisedCosineLinearEval(15).set_input_shape(1)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa67c0",
   "metadata": {},
   "source": [
    "- Cross-validate as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d238c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.GridSearchCV(pipe, param_grid, cv=cv_folds)\n",
    "cv.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15e9b80",
   "metadata": {},
   "source": [
    "- Investigate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07dbef",
   "metadata": {},
   "source": [
    "- Can easily grab the best estimator, the pipeline that did the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estim = cv.best_estimator_\n",
    "best_estim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ac64b",
   "metadata": {},
   "source": [
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54536119",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(best_estim, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c4cac",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e298a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates an empty array (n_sample, 0)\n",
    "def func(x):\n",
    "    return np.zeros((x.shape[0], 0))\n",
    "\n",
    "# Create a null basis using the custom basis class\n",
    "null_basis = nmo.basis.CustomBasis([func]).to_transformer()\n",
    "\n",
    "# this creates an empty feature\n",
    "null_basis.compute_features(position).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d738846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we note that the position + speed basis is in the basis attribute\n",
    "print(pipe[\"basis\"].basis)\n",
    "\n",
    "position_bas = nmo.basis.MSplineEval(n_basis_funcs=10).to_transformer()\n",
    "speed_bas = nmo.basis.MSplineEval(n_basis_funcs=15).to_transformer()\n",
    "\n",
    "# define 2D basis per each model \n",
    "basis_all = position_bas + speed_bas\n",
    "basis_position = position_bas + null_basis\n",
    "basis_speed = null_basis + speed_bas\n",
    "\n",
    "# assign label (not necessary but nice)\n",
    "basis_all.label = \"position + speed\"\n",
    "basis_position.label = \"position\"\n",
    "basis_speed.label = \"speed\"\n",
    "\n",
    "\n",
    "# then we create a parameter grid defining a grid of 2D basis for each model of interest\n",
    "param_grid = {\n",
    "    \"basis__basis\": \n",
    "    [\n",
    "        basis_all,  \n",
    "        basis_position, \n",
    "        basis_speed \n",
    "    ],\n",
    "}\n",
    "\n",
    "# finally we define and fit our CV\n",
    "cv = model_selection.GridSearchCV(pipe, param_grid, cv=cv_folds)\n",
    "cv.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(cv.cv_results_)\n",
    "\n",
    "# let's just plot a minimal subset of cols\n",
    "cv_df[[\"param_basis__basis\", \"mean_test_score\", \"rank_test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fec32d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    "\n",
    "The data in this tutorial comes from [Grosmark, Andres D., and György Buzsáki. \"Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences.\" Science 351.6280 (2016): 1440-1443](https://www.science.org/doi/full/10.1126/science.aad1935)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb5684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.18.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   42,
   66,
   93,
   101,
   107,
   113,
   118,
   126,
   131,
   139,
   144,
   153,
   158,
   168,
   179,
   189,
   206,
   214,
   216,
   223,
   227,
   267,
   271,
   278,
   281,
   291,
   294,
   306,
   313,
   324,
   334,
   342,
   346,
   357,
   367,
   395,
   405,
   412,
   415,
   423,
   425,
   433,
   437,
   449,
   454,
   463,
   467,
   475,
   477,
   485,
   494,
   501,
   519,
   527,
   534,
   541,
   550,
   557,
   559,
   570,
   578,
   585,
   587,
   595,
   597,
   607,
   609,
   618,
   621,
   632,
   639,
   646,
   649,
   656,
   658,
   665,
   668,
   676,
   680,
   684,
   696,
   729,
   734,
   746
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}