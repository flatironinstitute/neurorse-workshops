{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0730a26",
   "metadata": {
    "tags": [
     "hide-input",
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"plotting functions contained within `_documentation_utils` are intended for nemos's documentation.\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Ignoring cached namespace 'core'\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"invalid value encountered in div \"\n",
    "    ),\n",
    "    category=RuntimeWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6db53e",
   "metadata": {},
   "source": [
    ":::{admonition} Download\n",
    ":class: important render-all\n",
    "\n",
    "This notebook can be downloaded as **{nb-download}`nemos_advanced-presenters.ipynb`**. See the button at the top right to download as markdown or pdf.\n",
    "\n",
    ":::\n",
    "\n",
    "# NeMoS Advanced: Cross-Validation and Model Selection\n",
    "This notebook has had all its explanatory text removed and has not been run.\n",
    " It is intended to be downloaded and run locally (or on the provided binder)\n",
    " while listening to the presenter's explanation. In order to see the fully\n",
    " rendered of this notebook, go [here](../../full/day2/nemos_advanced.md)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In this tutorial we will keep working on the hippocampal place field recordings with the goal of learning how to combine NeMoS and scikit-learn to perform cross-validation and model selection. In particular we will:\n",
    "\n",
    "- Learn how to use NeMoS objects with [scikit-learn](https://scikit-learn.org/) for cross-validation\n",
    "- Learn how to use NeMoS objects with scikit-learn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- Learn how to use cross-validation to perform model and feature selection. More specifically, we will compare models including position and speed as predictors with model including only speed or only position.\n",
    "\n",
    "\n",
    "\n",
    "## Pre-Processing\n",
    "\n",
    "\n",
    "\n",
    "Let's first load and wrangle the data with pynapple and NeMoS. You can run the following cells for preparing the variables that we are going to use in the notebook and recapitulate the content of this dataset with a few visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a484d",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "\n",
    "import nemos as nmo\n",
    "\n",
    "# some helper plotting functions\n",
    "from nemos import _documentation_utils as doc_plots\n",
    "import workshop_utils\n",
    "\n",
    "# configure plots some\n",
    "plt.style.use(nmo.styles.plot_style)\n",
    "\n",
    "import workshop_utils\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "\n",
    "# shut down jax to numpy conversion warning\n",
    "nap.nap_config.suppress_conversion_warnings = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9984b6",
   "metadata": {},
   "source": [
    "- Load the data using pynapple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9d5fd",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "path = workshop_utils.fetch_data(\"Achilles_10252013_EEG.nwb\")\n",
    "data = nap.load_file(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a36623",
   "metadata": {},
   "source": [
    "- Extract the spike times and mouse position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dff694",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = data[\"units\"]\n",
    "position = data[\"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12080e05",
   "metadata": {},
   "source": [
    "- Restrict data to when animal was traversing the linear track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5d2db",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "position = position.restrict(data[\"forward_ep\"])\n",
    "spikes = spikes.restrict(data[\"forward_ep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbbb996",
   "metadata": {},
   "source": [
    "- Restrict neurons to only excitatory neurons, discarding neurons with a low-firing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24fb30",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = spikes.getby_category(\"cell_type\")[\"pE\"]\n",
    "spikes = spikes.getby_threshold(\"rate\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456f351",
   "metadata": {},
   "source": [
    "### Place fields\n",
    "\n",
    "\n",
    "\n",
    "- Visualize the *place fields*: neuronal firing rate as a function of position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcb811f",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "place_fields = nap.compute_tuning_curves(spikes, position, bins=50, epochs=position.time_support, feature_names=[\"distance\"])\n",
    "workshop_utils.plot_place_fields(place_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb9431",
   "metadata": {},
   "source": [
    "- For speed, we're only going to investigate the three neurons highlighted above.\n",
    "- Bin spikes to counts at 100 Hz.\n",
    "- Interpolate position to match spike resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c0510",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "neurons = [82, 92, 220]\n",
    "place_fields = place_fields.sel(unit=neurons)\n",
    "spikes = spikes[neurons]\n",
    "bin_size = .01\n",
    "count = spikes.count(bin_size, ep=position.time_support)\n",
    "position = position.interpolate(count, ep=count.time_support)\n",
    "print(count.shape)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee68948",
   "metadata": {},
   "source": [
    "### Extract Speed per Epoch\n",
    "\n",
    "\n",
    "\n",
    "- Compute the animal's speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c9d11",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "speed = []\n",
    "# Analyzing each epoch separately avoids edge effects.\n",
    "for s, e in position.time_support.values: \n",
    "    pos_ep = position.get(s, e)\n",
    "    # Absolute difference of two consecutive points\n",
    "    speed_ep = np.abs(np.diff(pos_ep)) \n",
    "    # Padding the edge so that the size is the same as the position/spike counts\n",
    "    speed_ep = np.pad(speed_ep, [0, 1], mode=\"edge\") \n",
    "    # Converting to cm/s \n",
    "    speed_ep = speed_ep * position.rate\n",
    "    speed.append(speed_ep)\n",
    "\n",
    "speed = nap.Tsd(t=position.t, d=np.hstack(speed), time_support=position.time_support)\n",
    "print(speed.shape)\n",
    "\n",
    "# utility function to visualize predictions\n",
    "tc_speed = nap.compute_tuning_curves(spikes, speed, bins=20, epochs=speed.time_support, feature_names=[\"speed\"])\n",
    "\n",
    "def visualize_model_predictions(glm, X):\n",
    "    # predict the model's firing rate\n",
    "    predicted_rate = glm.predict(X) / bin_size\n",
    "\n",
    "    # compute the position and speed tuning curves using the predicted firing rate.\n",
    "    glm_pos = nap.compute_tuning_curves(predicted_rate, position, bins=50, epochs=position.time_support, feature_names=[\"position\"])\n",
    "    glm_speed = nap.compute_tuning_curves(predicted_rate, speed, bins=30, epochs=position.time_support, feature_names=[\"speed\"])\n",
    "\n",
    "    workshop_utils.plot_position_speed_tuning(place_fields, tc_speed, glm_pos, glm_speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc20b00",
   "metadata": {},
   "source": [
    "### Define 1D NeMoS Bases \n",
    "\n",
    "\n",
    "\n",
    "- Define the position and speed bases, and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213673b7",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\")\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15, label=\"speed\")\n",
    "workshop_utils.plot_pos_speed_bases(position_basis, speed_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed1e2e",
   "metadata": {},
   "source": [
    "## Basis Composition\n",
    "\n",
    "\n",
    "\n",
    "- Adding the position and speed bases together defines a 2D basis.\n",
    "- Call `compute_features` to define a design matrix that concatenates both features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = position_basis + speed_basis\n",
    "\n",
    "X = basis.compute_features(position, speed)\n",
    "X_numpy = np.concatenate(\n",
    "    [\n",
    "        position_basis.compute_features(position),\n",
    "        speed_basis.compute_features(speed),\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Are the design matrices equivalent?\", np.all(X.d == X_numpy.d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c584e51",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "\n",
    "### How to know when to regularize?\n",
    "\n",
    "\n",
    "\n",
    "- How do we decide when to use regularization?\n",
    "- Cross-validation allows you to fairly compare different models on the same dataset.\n",
    "- NeMoS makes use of [scikit-learn](https://scikit-learn.org/), the standard machine learning library in python.\n",
    "- Define [parameter grid](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) to search over.\n",
    "- Anything not specified in grid will be kept constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Ridge GLM\n",
    "glm = nmo.glm.PopulationGLM(\n",
    "    regularizer=\"Ridge\",\n",
    "    solver_kwargs={\"tol\": 1e-12},\n",
    "    solver_name=\"LBFGS\",\n",
    ")\n",
    "param_grid = {\n",
    "    \"regularizer_strength\": [0.0001, 1.],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5e10f",
   "metadata": {},
   "source": [
    "- Initialize scikit-learn's [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_folds = 5\n",
    "cv = model_selection.GridSearchCV(glm, param_grid, cv=cv_folds)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75921b51",
   "metadata": {},
   "source": [
    "- We interact with this in a very similar way to the glm object.\n",
    "- In particular, call `fit` with same arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd91770",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837e5e5",
   "metadata": {},
   "source": [
    "- Let's investigate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2716e5",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1db0e",
   "metadata": {},
   "source": [
    "### Select basis\n",
    "\n",
    "\n",
    "\n",
    "- You can (and should) do something similar to determine how many basis functions you need for each input.\n",
    "- NeMoS basis objects are not scikit-learn-compatible right out of the box.\n",
    "- But we have provided a simple method to make them so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\").to_transformer()\n",
    "# or equivalently:\n",
    "position_basis = nmo.basis.TransformerBasis(nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\"))\n",
    "position_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541fe38",
   "metadata": {},
   "source": [
    "- This gives the basis object the `transform` method, which is equivalent to `compute_features`.\n",
    "- However, transformers have some limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b3064",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "position_basis.transform(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270a1d4",
   "metadata": {},
   "source": [
    "- Transformers only accept 2d inputs, whereas nemos basis objects can accept inputs of any dimensionality.\n",
    "- In order to use a basis as a transformer, you'll need to concatenate all your input in a single 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f88059",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis.transform(position[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1959a041",
   "metadata": {},
   "source": [
    "<div class=\"render-all\">\n",
    "\n",
    ":::{dropdown} Other Caveats\n",
    ":color: info\n",
    ":icon: info\n",
    "\n",
    "\n",
    "If the basis has more than one component (for example, if it is the addition of two 1D bases), the transformer will expect an input shape of `(n_sampels, 1)` pre component. If that's not the case, you'll provide a different input shape by calling `set_input_shape`.\n",
    "\n",
    "**Case 1)** One input per component:\n",
    "\n",
    "```{code-block} ipython3\n",
    "# generate a composite basis\n",
    "basis_2d = nmo.basis.MSplineEval(5) + nmo.basis.MSplineEval(5)\n",
    "basis_2d = basis_2d.to_transformer()\n",
    "\n",
    "# this will work: 1 input per component\n",
    "x, y = np.random.randn(10, 1), np.random.randn(10, 1)\n",
    "X = np.concatenate([x, y], axis=1)\n",
    "result = basis_2d.transform(X)\n",
    "```\n",
    "\n",
    "**Case 2)** Multiple inputs per component.\n",
    "\n",
    "\n",
    "- If one or more basis process multiple inputs (multiple columns of the 2D array), trying to call the `tranform` method directly will lead to an error. \n",
    "- This is because the basis doesn't know which component should process which column. \n",
    "\n",
    "\n",
    "```{code-block} ipython3\n",
    ":tags: [raises-exception, render-all]\n",
    "\n",
    "# Assume 2 input for the first component and 3 for the second.\n",
    "x, y = np.random.randn(10, 2), np.random.randn(10, 3)\n",
    "X = np.concatenate([x, y], axis=1)\n",
    "\n",
    "res = basis_2d.transform(X)  # This will raise an exception!\n",
    "```\n",
    "\n",
    "To prevent that, use `set_input_shape` to define how many inputs each component should process.\n",
    "\n",
    "```{code-block} ipython3\n",
    "# Set the expected input shape instead, different options:\n",
    "\n",
    "# array\n",
    "res1 = basis_2d.set_input_shape(x, y).transform(X)\n",
    "# int\n",
    "res2 = basis_2d.set_input_shape(2, 3).transform(X)\n",
    "# tuple\n",
    "res3 = basis_2d.set_input_shape((2,), (3,)).transform(X)\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "- Let's now create the composite basis for speed and position.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10, label=\"position\")\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15, label=\"speed\")\n",
    "basis = position_basis + speed_basis\n",
    "basis = basis.to_transformer()\n",
    "basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff17051",
   "metadata": {},
   "source": [
    "- Stack position and speed in a single TsdFrame to hold all our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673102a9",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "transformer_input = nap.TsdFrame(\n",
    "    t=position.t,\n",
    "    d=np.stack([position, speed]).T,\n",
    "    time_support=position.time_support,\n",
    "    columns=[\"position\", \"speed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189b22d",
   "metadata": {},
   "source": [
    "- Pass this input to our transformed additive basis. \n",
    "- Note that we do not need to call `set_input_shape` here because each basis element processes one column of the 2D input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd404a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis.transform(transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bb16b",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "\n",
    "\n",
    "- If we want to cross-validate over the basis, we need more one more step: combining the basis and the GLM into a single scikit-learn estimator.\n",
    "- [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de4aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the reg strength to the optimal\n",
    "glm = nmo.glm.PopulationGLM(solver_name=\"LBFGS\", solver_kwargs={\"tol\": 10**-12})\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"basis\", basis),\n",
    "    (\"glm\", glm)\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e3dd7",
   "metadata": {},
   "source": [
    "- Pipeline runs `basis.transform`, then passes that output to `glm`, so we can do everything in a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a94ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e2184f",
   "metadata": {},
   "source": [
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb497b18",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(pipe, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43bb4cc",
   "metadata": {},
   "source": [
    "### Cross-validating on the basis\n",
    "\n",
    "\n",
    "\n",
    "Now that we have our pipeline estimator, we can cross-validate on any of its parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2e16e",
   "metadata": {},
   "source": [
    "Let's cross-validate on:\n",
    "- The number of the basis functions of the position basis\n",
    "- The functional form of the basis for speed\n",
    "- Let's retrieve the those attributes from the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74378344",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# the label of the pipeline step retrieves the basis\n",
    "print(pipe[\"basis\"])\n",
    "\n",
    "# the position basis can by retreived by its label\n",
    "print(\"\\n\", pipe[\"basis\"][\"position\"])\n",
    "\n",
    "# the n_basis_funcs is an attribute\n",
    "print(\"\\n\", pipe[\"basis\"][\"position\"].n_basis_funcs)\n",
    "\n",
    "# with the same syntax we can retreive the speed basis\n",
    "print(\"\\n\", pipe[\"basis\"][\"speed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51379f",
   "metadata": {},
   "source": [
    "- Construct `param_grid`, using `__` to stand in for `.`\n",
    "- In scikit-learn pipelines, we access nested parameters using double underscores:\n",
    "  - `pipe[\"basis\"][\"position\"].n_basis_funcs` ← normal Python syntax\n",
    "  - `\"basis__position__n_basis_funcs\"` ← scikit-learn parameter grid syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"basis__position__n_basis_funcs\": [5, 10, 20],\n",
    "    \"basis__speed\": [nmo.basis.MSplineEval(15),\n",
    "                      nmo.basis.BSplineEval(15),\n",
    "                      nmo.basis.RaisedCosineLinearEval(15)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a654abd",
   "metadata": {},
   "source": [
    "- Cross-validate as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.GridSearchCV(pipe, param_grid, cv=cv_folds)\n",
    "cv.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36ba1d",
   "metadata": {},
   "source": [
    "- Investigate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff5cdd",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be9bbf",
   "metadata": {},
   "source": [
    "- Can easily grab the best estimator, the pipeline that did the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b20ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estim = cv.best_estimator_\n",
    "best_estim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2674c52",
   "metadata": {},
   "source": [
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad21dd5",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(best_estim, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694bf23",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "\n",
    "\n",
    "Let's move on to feature selection. Our goal is comparing alternative models, for this example we will consider: position + speed, position only or speed only.\n",
    "\n",
    "Problem: scikit-learn's cross-validation assumes that the input to the pipeline does not change, while each model will have a different input. What can we do? \n",
    "\n",
    "Let's see how to circumvent this with a neat basis trick.\n",
    "\n",
    "- Create a \"null\" basis that produces zero features using `CustomBasis`, which defines a basis from a list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af42f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates an empty array (n_sample, 0)\n",
    "def func(x):\n",
    "    return np.zeros((x.shape[0], 0))\n",
    "\n",
    "# Create a null basis using the custom basis class\n",
    "null_basis = nmo.basis.CustomBasis([func]).to_transformer()\n",
    "\n",
    "# this creates an empty feature\n",
    "null_basis.compute_features(position).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f8c81",
   "metadata": {},
   "source": [
    "- First we can note that the original \"position + speed\" additive basis is the `basis` attribute of the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac675ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[\"basis\"].basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276e131",
   "metadata": {},
   "source": [
    "- Add the null basis to the speed or position basis to generate a composite basis for the position-only and speed-only model that receives the same 2D input as the model including all predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the 1D transformer bases with no label\n",
    "position_bas = nmo.basis.MSplineEval(n_basis_funcs=10).to_transformer()\n",
    "speed_bas = nmo.basis.MSplineEval(n_basis_funcs=15).to_transformer()\n",
    "\n",
    "# combine them with each other or with the null basis to define each model.\n",
    "basis_all = position_bas + speed_bas\n",
    "basis_position = position_bas + null_basis\n",
    "basis_speed = null_basis + speed_bas\n",
    "\n",
    "# assign label (not necessary but nice)\n",
    "basis_all.label = \"position + speed\"\n",
    "basis_position.label = \"position\"\n",
    "basis_speed.label = \"speed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa65525f",
   "metadata": {},
   "source": [
    "- Create a parameter grid for each model of interest. \n",
    "- The attribute to cross-validate over is `\"basis__basis\"`, where the first \"basis\" is the name of the pipeline step, the second one is the attribute of the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d694825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we create a parameter grid defining a grid of 2D basis for each model of interest\n",
    "param_grid = {\n",
    "    \"basis__basis\": \n",
    "    [\n",
    "        basis_all,  \n",
    "        basis_position, \n",
    "        basis_speed \n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963501f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally we define and fit our CV\n",
    "cv = model_selection.GridSearchCV(pipe, param_grid, cv=cv_folds)\n",
    "cv.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca9eb1",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(cv.cv_results_)\n",
    "\n",
    "# let's just plot a minimal subset of cols\n",
    "cv_df[[\"param_basis__basis\", \"mean_test_score\", \"rank_test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a290871",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\n",
    "\n",
    "Various combinations of features can lead to different results. From this quick demo it looks like the position-only model is only marginally worst compared to the full model. \n",
    "\n",
    "  - [Hardcastle, Kiah, et al. \"A multiplexed, heterogeneous, and adaptive code for navigation in medial entorhinal cortex.\" Neuron 94.2 (2017): 375-387](https://www.cell.com/neuron/pdf/S0896-6273(17)30237-4.pdf)\n",
    "\n",
    "  - [McClain, Kathryn, et al. \"Position–theta-phase model of hippocampal place cell activity applied to quantification of running speed modulation of firing rate.\" Proceedings of the National Academy of Sciences 116.52 (2019): 27035-27042](https://www.pnas.org/doi/abs/10.1073/pnas.1912792116)\n",
    "\n",
    "  - [Peyrache, Adrien, Natalie Schieferstein, and Gyorgy Buzsáki. \"Transformation of the head-direction signal into a spatial code.\" Nature communications 8.1 (2017): 1752.](https://www.nature.com/articles/s41467-017-01908-3)\n",
    "\n",
    "## Project Ideas\n",
    "\n",
    "Use what you learned here and compare models including the theta phase. You can model phase precession as an interaction term between position and theta phase; You can include an interaction term by using the basis multiplication operator, for more information see,\n",
    "\n",
    "- [Background on basis composition](https://nemos.readthedocs.io/en/latest/background/basis/plot_02_ND_basis_function.html)\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "The data in this tutorial comes from [Grosmark, Andres D., and György Buzsáki. \"Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences.\" Science 351.6280 (2016): 1440-1443](https://www.science.org/doi/full/10.1126/science.aad1935)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.18.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   42,
   78,
   103,
   109,
   115,
   121,
   126,
   134,
   139,
   147,
   152,
   161,
   166,
   176,
   187,
   197,
   227,
   237,
   243,
   254,
   268,
   284,
   294,
   302,
   306,
   314,
   316,
   323,
   327,
   339,
   345,
   354,
   358,
   367,
   369,
   430,
   436,
   444,
   453,
   462,
   465,
   476,
   484,
   491,
   493,
   501,
   505,
   515,
   517,
   527,
   541,
   552,
   559,
   567,
   570,
   578,
   582,
   590,
   593,
   601,
   605,
   621,
   631,
   638,
   641,
   648,
   662,
   670,
   682,
   688,
   695
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}