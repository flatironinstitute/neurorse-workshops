{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152098a4",
   "metadata": {
    "tags": [
     "hide-input",
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"plotting functions contained within `_documentation_utils` are intended for nemos's documentation.\",\n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24612c93",
   "metadata": {},
   "source": [
    ":::{admonition} Download\n",
    ":class: important render-all\n",
    "\n",
    "This notebook can be downloaded as **{nb-download}`01_head_direction-users.ipynb`**. See the button at the top right to download as markdown or pdf.\n",
    ":::\n",
    "# Analyzing head-direction cells with Pynapple and Nemos\n",
    "This notebook has had all its explanatory text removed and has not been run.\n",
    " It is intended to be downloaded and run locally (or on the provided binder),\n",
    " working through the questions with your small group.\n",
    "\n",
    "\n",
    "\n",
    "In this tutorial, we will learn how to use pynapple and nemos to analyze head-direction cells recorded in the \n",
    "anterodorsal thalamic nucleus (ADn) of the mouse. We will use a NWB file containing spike times of neurons and the head-direction of the animal over time.\n",
    "We will study the relationship between neurons during wakefulness and sleep with cross-correlograms.\n",
    "Finally, we will fit a generalized linear model (GLM) to quantify the functional connectivity between neurons based on their spike history.\n",
    "\n",
    "The pynapple documentation can be found [here](https://pynapple.org).\n",
    "\n",
    "The nemos documentation can be found [here](https://nemos.readthedocs.io/en/latest/).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "\n",
    "For part 1 of the tutorial, we will use pynapple to do the following tasks:\n",
    "1. Loading a NWB file\n",
    "2. Compute tuning curves\n",
    "3. Compute cross-correlograms\n",
    "\n",
    "For part 2 of the tutorial, we will use nemos to do the following tasks:\n",
    "1. Create spike history features\n",
    "2. Fit a GLM model to a single neuron\n",
    "3. Fit a GLM model with basis functions to reduce over-fitting\n",
    "4. Fit a GLM model to all neurons to learn functional connectivity\n",
    "\n",
    "Let's start by importing all the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2249eb4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "import workshop_utils\n",
    "import pynapple as nap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nemos as nmo\n",
    "\n",
    "# some helper plotting functions\n",
    "from nemos import _documentation_utils as doc_plots\n",
    "import workshop_utils\n",
    "\n",
    "# configure pynapple to ignore conversion warning\n",
    "nap.nap_config.suppress_conversion_warnings = True\n",
    "\n",
    "# configure plots some\n",
    "plt.style.use(nmo.styles.plot_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4eee6",
   "metadata": {},
   "source": [
    "## Part 1 : Analyzing head-direction cells with Pynapple\n",
    "### Fetch and load data\n",
    "\n",
    "\n",
    "The dataset we will use is from this study : [Peyrache et al., 2015](https://www.nature.com/articles/nn.3968).\n",
    "\n",
    "If you ran the workshop setup script, you should have this file downloaded already. \n",
    "If not, the function we'll use to fetch it will download it for you. \n",
    "This function is called `fetch_data`, and can be imported from the `workshop_utils` module. \n",
    "This function will give us the file path to where the data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316a128",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "path = workshop_utils.fetch_data(\"Mouse32-140822.nwb\")\n",
    "\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde21270",
   "metadata": {},
   "source": [
    "Pynapple provides the convenience function `nap.load_file` for loading a NWB file.\n",
    "\n",
    "**Question:** Can you open the NWB file giving the variable `path` to the function `load_file` and call the output `data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aeafb4",
   "metadata": {},
   "source": [
    "The content of the NWB file is not loaded yet. The object `data` behaves like a dictionary.\n",
    "It contains multiple entries corresponding to different data types stored in the NWB file.\n",
    "In NWB files, spike times are stored in the `units` entry.\n",
    "\n",
    "**Question:** Can you load the spike times from the NWB and call the variables `spikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dadec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes =   # Get spike timings\n",
    "print(spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71913f6",
   "metadata": {},
   "source": [
    "There are a lot of neurons. The neurons that interest us are the neurons labeled `adn`. \n",
    "\n",
    "**Question:** Using the slicing method of your choice, can you select only the neurons in `adn` that are above 2 Hz firing rate?\n",
    "\n",
    "THere multiple options here. As a reminder, metadatas can be accessed like a dictionary or as attributes. There are also\n",
    "functions that can help you filter neurons based on metadata.\n",
    "\n",
    "1. `spikes.label` returns a pandas Series with the metadata of the neurons.\n",
    "2. `spikes['label']` returns a pandas Series with the metadata of the neurons.\n",
    "3. Functions like [`spikes.getby_category`](https://pynapple.org/generated/pynapple.TsGroup.getby_category.html#pynapple.TsGroup.getby_category)\n",
    "    or [`spikes.getby_threshold`](https://pynapple.org/generated/pynapple.TsGroup.getby_threshold.html#pynapple.TsGroup.getby_threshold) can help you filter neurons based on metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336015ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes =   # Select only ADN neurons with rate > 2.0 Hz\n",
    "print(len(spikes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c43f6",
   "metadata": {},
   "source": [
    "The NWB file contains other information about the recording. `ry` contains the value of the head-direction of the animal over time. \n",
    "\n",
    "**Question:** Can you extract the angle of the animal in a variable called `angle` and print it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle =   # Get head-direction data from NWB object\n",
    "print(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b195a3",
   "metadata": {},
   "source": [
    "But are the data actually loaded  or not?\n",
    "If you look at the type of `angle`, you will see that it is a `Tsd` object.\n",
    "But what about the underlying data array?\n",
    "The underlying data array is stored in the property `d` of the `Tsd` object.\n",
    "If you print it, you will see that it is a `h5py` array.\n",
    "By default, data are lazy-loaded. This can be useful when reading larger than memory array from disk with memory map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba82f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8868b142",
   "metadata": {},
   "source": [
    "The animal was recorded during wakefulness and sleep. \n",
    "\n",
    "**Question:** Can you extract the behavioral intervals in a variable called `epochs`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =   # Get behavioral epochs from NWB object\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c16e0",
   "metadata": {},
   "source": [
    "NWB file can save intervals with multiple labels. The object `IntervalSet` includes the labels as a metadata object.\n",
    "\n",
    "**Question:** Using the column `tags`, can you create one `IntervalSet` object for intervals labeled `wake` and one `IntervalSet` object for intervals labeled `sleep`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5e139",
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_ep =  # Get wake intervals from epochs\n",
    "sleep_ep =  # Get sleep intervals from epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4bc3f",
   "metadata": {},
   "source": [
    "### Compute tuning curves\n",
    "\n",
    "\n",
    "Now we have \n",
    "- spikes\n",
    "- a behavioral feature (i.e. head-direction), \n",
    "- epochs corresponding to when the feature is defined (i.e. when the head-direction was recorded).\n",
    "\n",
    "We can compute tuning curves, i.e. the firing rate of neurons as a function of head-direction. \n",
    "We want to know how the firing rate of each neuron changes as a function of the head-direction of the animal during wakefulness.\n",
    "\n",
    "To do this in pynapple, all you need is the call of a single function : `nap.compute_tuning_curves`!\n",
    "\n",
    "**Question:** can you compute the firing rate of ADn units as a function of heading direction, i.e. a head-direction tuning curve and call the variable `tuning_curves`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_curves = nap.compute_tuning_curves(\n",
    "    data=, # The neural activity as a TsGroup\n",
    "    features=, # Which feature? Here the head-direction of the animal\n",
    "    bins=, # How many bins of feature space? Here 61 angular bins is a good numbers\n",
    "    epochs = angle.time_support, # The epochs should correspond to when the features are defined. Here we use the time support directly\n",
    "    range= (0, 2*np.pi), # The min and max of the bin array\n",
    "    feature_names = [\"angle\"] # Let's give a name to our feature for better labelling of the output.\n",
    "    ) \n",
    "tuning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce528ce1",
   "metadata": {},
   "source": [
    "The output is a xarray object indexed by neuron and head\\-direction: the first dimension corresponds to neurons, \n",
    "the second to angular bins, and additional metadata fields are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2036f7",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.subplot(221)\n",
    "tuning_curves[0].plot()\n",
    "# plt.plot(tuning_curves[0])\n",
    "plt.subplot(222,projection='polar')\n",
    "plt.plot(tuning_curves.angle, tuning_curves[0].values)\n",
    "plt.subplot(223)\n",
    "tuning_curves[1].plot()\n",
    "plt.subplot(224,projection='polar')\n",
    "plt.plot(tuning_curves.angle, tuning_curves[1].values)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a1e3c",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-00.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "Most of those neurons are head-directions neurons.\n",
    "\n",
    "The next cell allows us to get a quick estimate of the neurons's preferred direction. \n",
    "Since this is a lot of xarray wrangling, it is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465e638",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "pref_ang = tuning_curves.idxmax(dim=\"angle\")\n",
    "\n",
    "print(pref_ang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c65ff6",
   "metadata": {},
   "source": [
    "The variable `pref_ang` contains the preferred direction of each neuron. \n",
    "Now this information can be useful to add it to the metainformation of the `spikes` object since it is neuron-specific information.\n",
    "\n",
    "**Question:** Can you add it to the metainformation of `spikes`? The metadata field should be called `pref_ang`.\n",
    "\n",
    "Hint :\n",
    "\n",
    "There are multiple ways of doing this:\n",
    "```\n",
    "tsgroup['label'] = metadata\n",
    "tsgroup.label = metadata\n",
    "tsgroup.set_info(label=metadata)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148706ca",
   "metadata": {},
   "source": [
    "This index maps a neuron to a preferred angular direction between 0 and 2pi. \n",
    "Let's visualize the spiking activity of the neurons based on their preferred direction \n",
    "as well as the head-direction of the animal. To make it easier to see, we will restrict the data to a small epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5651e7",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "ex_ep = nap.IntervalSet(start=8910, end=8960)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(angle.restrict(ex_ep))\n",
    "plt.ylim(0, 2*np.pi)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(spikes.restrict(ex_ep).to_tsd(\"pref_ang\"), '|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a617ce0d",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-01.png)\n",
    ":::\n",
    "\n",
    "### Compute correlograms\n",
    "\n",
    "\n",
    "We see that some neurons have a correlated activity meaning they tend to fire together, while others have an anti-correlated activity meaning when one neuron fires, the other does not.\n",
    "Can we quantify this correlation between pairs of neurons? To do this, we can compute cross-correlograms between pairs of neurons.\n",
    "A cross-correlogram measures the correlation between the spike trains of two neurons as a function of time lag. It counts how often spikes from one neuron occur at different time lags relative to spikes from another neuron.\n",
    "In pynapple, we use the function `nap.compute_crosscorrelogram` to compute cross-correlograms between pairs of neurons.\n",
    "\n",
    "**Question:** Can you compute cross-correlograms during wake for all pairs of neurons and call it `cc_wake`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_wake = nap.compute_crosscorrelogram(\n",
    "    data=, # The neural activity as a TsGroup\n",
    "    binsize=, # I suggest 200 ms bin\n",
    "    windowsize=, # Let's do a 20 s window\n",
    "    ep= # Which epoch to restrict the cross-correlograms. Here is it should be wakefulness.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341f9db",
   "metadata": {},
   "source": [
    "The output is a pandas DataFrame where each column is a pair of neurons. All pairs of neurons are computed automatically.\n",
    "The index shows the time lag.\n",
    "Let's visualize some cross-correlograms. \n",
    "To make things easier, we will focus on two pairs of neurons: one pair that fires for the same direction and one pair that fires for opposite directions.\n",
    "\n",
    "The pair (7, 20) fires for the same direction while the pair (7, 26) fires for opposite directions. \n",
    "\n",
    "To index pandas columns, you can do `cc[(7, 20)]`.\n",
    "\n",
    "To index xarray tuning curves, you can do `tuning_curves.sel(unit=[7,20])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f679b83",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "index = spikes.keys()\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(221)\n",
    "tuning_curves.sel(unit=[7,20]).plot(x='angle', hue='unit')\n",
    "plt.title(\"Tuning curves\")\n",
    "plt.subplot(222)\n",
    "plt.plot(cc_wake[(7, 20)])\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.title(\"Cross-corr.\")\n",
    "plt.subplot(223)\n",
    "tuning_curves.sel(unit=[7,26]).plot(x='angle', hue='unit')\n",
    "plt.title(\"Tuning curves\")\n",
    "plt.subplot(224)\n",
    "plt.plot(cc_wake[(7, 26)])\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.title(\"Cross-corr.\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a7d36",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-02.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "As you can see, the pair of neurons that fire for the same direction have a positive correlation at time lag 0, meaning they tend to fire together.\n",
    "The pair of neurons that fire for opposite directions have a negative correlation at time lag 0, meaning when one neuron fires, the other does not.\n",
    "\n",
    "Pairwise correlation were computed during wakefulness. The activity of the neurons was also recorded during sleep.\n",
    "\n",
    "**Question:** can you compute the cross-correlograms during sleep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1859e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_sleep = nap.compute_crosscorrelogram(\n",
    "    data=, # The neural activity as a TsGroup\n",
    "    binsize=, # I suggest 20 ms bin\n",
    "    windowsize=, # Let's do a 1 s window\n",
    "    ep= # Which epoch to restrict the cross-correlograms. Here is it should be sleep.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff7e2f",
   "metadata": {},
   "source": [
    "Let's visualize the cross-correlograms during wake and sleep for the pair of neurons that fire for the same direction \n",
    "and the pair of neurons that fire for opposite directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2ff81",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.subplot(231)\n",
    "tuning_curves.sel(unit=[7,20]).plot(x='angle', hue='unit')\n",
    "plt.title(\"Tuning curves\")\n",
    "plt.subplot(232)\n",
    "plt.plot(cc_wake[(7, 20)])\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.title(\"Wake\")\n",
    "plt.subplot(233)\n",
    "plt.plot(cc_sleep[(7, 20)])\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.title(\"Sleep\")\n",
    "plt.subplot(234)\n",
    "tuning_curves.sel(unit=[7,26]).plot(x='angle', hue='unit')\n",
    "plt.subplot(235)\n",
    "plt.plot(cc_wake[(7, 26)])\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.subplot(236)\n",
    "plt.plot(cc_sleep[(7, 26)])\n",
    "plt.xlabel(\"Time lag (s)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce453722",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-03.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "What does it mean for the relationship between cells here? Remember that during sleep, the animal is not moving and therefore the head-direction is not defined.\n",
    "\n",
    "\n",
    "## Part 2 : Fitting a GLM model with Nemos\n",
    "\n",
    "\n",
    "In the first part of the notebook, we characterized the relationship between head-direction cells during wake and sleep. Cells that fire together during wake also fire together during sleep and cells that don't fire together during wake don't fire together during sleep. The goal here is to characterized this relationship with generalized linear model. Since cells have a functional relationship to each other, the activity of one cell should predict the activity of another cell.\n",
    "\n",
    "**Question : are neurons constantly tuned to head-direction and can we use it to predict the spiking activity of each neuron based only on the activity of other neurons?**\n",
    "\n",
    "To fit the GLM faster, we will use only the first 3 min of wake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457ffae",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# restrict wake epoch to first 3 minutes\n",
    "wake_ep = nap.IntervalSet(\n",
    "    start=wake_ep.start[0], end=wake_ep.start[0] + 3 * 60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b98406",
   "metadata": {},
   "source": [
    "To use the GLM, we need first to bin the spike trains. Here we use pynapple and the function `count`.\n",
    "\n",
    "**Question: can you bin the spike trains in 10 ms bins during the `wake_ep` and call the variable `count`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 0.01\n",
    "count =   # Bin spike trains during wake_ep\n",
    "print(count.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52108c",
   "metadata": {},
   "source": [
    "Above we defined `pref_ang` as the preferred direction of each neuron. `np.argsort(pref_ang.values)` gives you the order to sort the columns of count.\n",
    "This is useful to visualize the activity of neurons based on their preferred direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6ba2c",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "count = count[:, np.argsort(pref_ang.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ec115",
   "metadata": {},
   "source": [
    "It's time to use NeMoS. Our end goal is to estimate the pairwise interaction between neurons.\n",
    "This can be quantified with a GLM if we use the recent population spike history to predict the current time step.\n",
    "\n",
    "To simplify our life, let's see first how we can model spike history effects in a single neuron.\n",
    "The simplest approach is to use counts in fixed length window $i$, $y_{t-i}, \\dots, y_{t-1}$ to predict the next\n",
    "count $y_{t}$. \n",
    "\n",
    "Before starting the analysis, let's \n",
    "\n",
    "- **select a neuron (first column is good) from the `count` object (call the variable `neuron_count`)** \n",
    "- **Select the first 1.2 seconds of wake_ep for visualization. (call the epoch `epoch_one_spk`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b415e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# select a neuron's spike count time series\n",
    "neuron_count = count[:, 0]\n",
    "\n",
    "# restrict to a smaller time interval\n",
    "epoch_one_spk = nap.IntervalSet(\n",
    "    start=count.time_support.start[0], end=count.time_support.start[0] + 1.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8e2da",
   "metadata": {},
   "source": [
    "### Features Construction\n",
    "\n",
    "\n",
    "Let's fix the spike history window size that we will use as predictor meaning how far back in time we want to look to predict the current rate.\n",
    "\n",
    "Let's :\n",
    "- Fix a history window of 800ms (0.8 seconds).\n",
    "- Plot the result using `doc_plots.plot_history_window`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c940fbbf",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# set the size of the spike history window in seconds\n",
    "window_size_sec = 0.8\n",
    "\n",
    "fig = doc_plots.plot_history_window(neuron_count, epoch_one_spk, window_size_sec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2f614",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-04.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "For each time point, we shift our window one bin at the time and vertically stack the spike count history in a matrix.\n",
    "Each row of the matrix will be used as the predictors for the rate in the next bin (red narrow rectangle in\n",
    "the figure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dc4d3",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "doc_plots.run_animation(neuron_count, epoch_one_spk.start[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f7283",
   "metadata": {},
   "source": [
    "If $t$ is smaller than the window size, we won't have a full window of spike history for estimating the rate.\n",
    "One may think of padding the window (with zeros for example) but this may generate weird border artifacts.\n",
    "To avoid that, we can simply restrict our analysis to times $t$ larger than the window and NaN-pad earlier\n",
    "time-points;\n",
    "\n",
    "You can construct this feature matrix with the [`HistoryConv`](https://nemos.readthedocs.io/en/latest/generated/basis/nemos.basis.HistoryConv.html#nemos.basis.HistoryConv) basis.\n",
    "\n",
    "**Question: Can you:**\n",
    "    - Convert the window size in number of bins (call it `window_size`)\n",
    "    - Define an `HistoryConv` basis covering this window size (call it `history_basis`).\n",
    "    - Create the feature matrix with `history_basis.compute_features` (call it `input_feature`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the prediction window to bins (by multiplying with the sampling rate)\n",
    "window_size = int(window_size_sec * neuron_count.rate)\n",
    "# define the history bases\n",
    "history_basis = # Parameter indicate the window size in bins\n",
    "# create the feature matrix\n",
    "input_feature =  # Using history_basis compute features on neuron_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc950a",
   "metadata": {},
   "source": [
    "NeMoS NaN pads if there aren't enough samples to predict the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59796e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# print the NaN indices along the time axis\n",
    "print(\"NaN indices:\\n\", np.where(np.isnan(input_feature[:, 0]))[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ed523c",
   "metadata": {},
   "source": [
    "The binned counts originally have shape \"number of samples\", we should check that the\n",
    "dimension are matching our expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a28ea",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Time bins in counts: {neuron_count.shape[0]}\")\n",
    "print(f\"Convolution window size in bins: {window_size}\")\n",
    "print(f\"Feature shape: {input_feature.shape}\")\n",
    "print(f\"Feature shape: {input_feature.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0da32",
   "metadata": {},
   "source": [
    "We can visualize the output for a few time bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b4c7c",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "suptitle = \"Input feature: Count History\"\n",
    "neuron_id = 0\n",
    "fig = workshop_utils.plot_features(input_feature, count.rate, suptitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebc1b4",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-05.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "As you may see, the time axis is backward, this happens because under the hood, the basis is using the convolution operator which flips the time axis.\n",
    "This is equivalent, as we can interpret the result as how much a spike will affect the future rate.\n",
    "In the previous tutorial our feature was 1-dimensional (just the current), now\n",
    "instead the feature dimension is 80, because our bin size was 0.01 sec and the window size is 0.8 sec.\n",
    "We can learn these weights by maximum likelihood by fitting a GLM.\n",
    "\n",
    "\n",
    "### Fitting a single neuron model\n",
    "\n",
    "\n",
    "When working a real dataset, it is good practice to train your models on a chunk of the data and\n",
    "use the other chunk to assess the model performance. This process is known as \"cross-validation\".\n",
    "There is no unique strategy on how to cross-validate your model; What works best\n",
    "depends on the characteristic of your data (time series or independent samples,\n",
    "presence or absence of trials), and that of your model. Here, for simplicity use the first\n",
    "half of the wake epochs for training and the second half for testing. This is a reasonable\n",
    "choice if the statistics of the neural activity does not change during the course of\n",
    "the recording. We will learn about better cross-validation strategies with other\n",
    "examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cb735",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# construct the train and test epochs\n",
    "duration = input_feature.time_support.tot_length(\"s\")\n",
    "start = input_feature.time_support[\"start\"]\n",
    "end = input_feature.time_support[\"end\"]\n",
    "\n",
    "# define the interval sets\n",
    "first_half = nap.IntervalSet(start, start + duration / 2)\n",
    "second_half = nap.IntervalSet(start + duration / 2, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d58596",
   "metadata": {},
   "source": [
    "**Question: Can you fit the glm to the first half of the recording and visualize the maximum likelihood weights?**\n",
    "\n",
    "The model used should be a `nmo.glm.GLM` with the solver `LBFGS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12595c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the GLM object\n",
    "model = nmo.glm.GLM() # Parameter is the solver name\n",
    "# Fit over the training epochs\n",
    "model.fit(\n",
    "    input_feature.restrict(), # Parameter is the feature matrix restricted to the first half\n",
    "    neuron_count.restrict() # Parameter is the binned spike count time series restricted to the first half\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed925d",
   "metadata": {},
   "source": [
    "The weights represent the effect of a spike at time lag $i$ on the rate at time $t$. The next cell display the learned weights.\n",
    "The model should be called `model` from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0c9a4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title(\"Spike History Weights\")\n",
    "plt.plot(np.arange(window_size) / count.rate, np.squeeze(model.coef_), lw=2, label=\"GLM raw history 1st Half\")\n",
    "plt.axhline(0, color=\"k\", lw=0.5)\n",
    "plt.xlabel(\"Time From Spike (sec)\")\n",
    "plt.ylabel(\"Kernel\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d8fc0",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-06.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "The response in the previous figure seems noise added to a decay, therefore the response\n",
    "can be described with fewer degrees of freedom. In other words, it looks like we\n",
    "are using way too many weights to describe a simple response.\n",
    "If we are correct, what would happen if we re-fit the weights on the other half of the data?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Question: Can you fit a new model on the second half of the data and call it `model_second_half`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b589e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the other half of the data\n",
    "model_second_half =  # Parameter is the solver name\n",
    "model_second_half.fit(\n",
    "    , # Parameter is the feature matrix restricted to the second half\n",
    "     # Parameter is the binned spike count time series restricted to the second half\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d61d4e",
   "metadata": {},
   "source": [
    "Let's plot the weights learned on the second half of the data and compare them to those learned on the first half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139faa4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title(\"Spike History Weights\")\n",
    "plt.plot(np.arange(window_size) / count.rate, np.squeeze(model.coef_),\n",
    "         label=\"GLM raw history 1st Half\", lw=2)\n",
    "plt.plot(np.arange(window_size) / count.rate,  np.squeeze(model_second_half.coef_),\n",
    "         color=\"orange\", label=\"GLM raw history 2nd Half\", lw=2)\n",
    "plt.axhline(0, color=\"k\", lw=0.5)\n",
    "plt.xlabel(\"Time From Spike (sec)\")\n",
    "plt.ylabel(\"Kernel\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fa360",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-07.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "What can we conclude?\n",
    "\n",
    "The fast fluctuations are inconsistent across fits, indicating that\n",
    "they are probably capturing noise, a phenomenon known as over-fitting;\n",
    "On the other hand, the decaying trend is fairly consistent, even if\n",
    "our estimate is noisy. You can imagine how things could get\n",
    "worst if we needed a finer temporal resolution, such 1ms time bins\n",
    "(which would require 800 coefficients instead of 80).\n",
    "What can we do to mitigate over-fitting now?\n",
    "\n",
    "\n",
    "### Reducing feature dimensionality\n",
    "\n",
    "Let's see how to use NeMoS' `basis` module to reduce dimensionality and avoid over-fitting!\n",
    "For history-type inputs, we'll use again the raised cosine log-stretched basis,\n",
    "[Pillow et al., 2005](https://www.jneurosci.org/content/25/47/11003)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40163ec3",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = doc_plots.plot_basis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b38de",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-08.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "We can initialize the `RaisedCosineLogConv` by providing the number of basis functions \n",
    "and the window size for the convolution. With more basis functions, we'll be able to represent \n",
    "the effect of the corresponding input with the higher precision, at the cost of adding additional parameters.\n",
    "\n",
    "**Question: Can you define the basis `RaisedCosineLogConv`and name it `basis`?**\n",
    "\n",
    "Basis parameters:\n",
    "- 8 basis functions.\n",
    "- Window size of 0.8sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d76541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a basis object can be instantiated in \"conv\" mode for convolving the input.\n",
    "basis = nmo.basis.RaisedCosineLogConv(\n",
    "    n_basis_funcs=, # Number of basis functions\n",
    "    window_size= # Window size in bins\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65e83e",
   "metadata": {},
   "source": [
    "Our spike history predictor was huge: every possible 80 time point chunk of the\n",
    "data, for $144 \\cdot 10^4$ total numbers. By using this basis set we can instead reduce\n",
    "the predictor to 8 numbers for every 80 time point window for $144 \\cdot 10^3$ total\n",
    "numbers, an order of magnitude less. With 1ms bins we would have\n",
    "achieved 2 order of magnitude reduction in input size. This is a huge benefit\n",
    "in terms of memory allocation and, computing time. As an additional benefit,\n",
    "we will reduce over-fitting.\n",
    "\n",
    "Let's see our basis in action. We can \"compress\" spike history feature by convolving the basis\n",
    "with the counts (without creating the large spike history feature matrix).\n",
    "This can be performed in NeMoS by calling the `compute_features` method of basis.\n",
    "\n",
    "**Question: Can you:**\n",
    "- Convolve the counts with the basis functions. (Call the output `conv_spk`)\n",
    "- Print the shape of `conv_spk` and compare it to `input_feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116118ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to\n",
    "# `nmo.convolve.create_convolutional_predictor(basis_kernels, neuron_count)`\n",
    "conv_spk = basis.compute_features() # Parameter is the binned spike count time series\n",
    "print(f\"Raw count history as feature: {input_feature.shape}\")\n",
    "print(f\"Compressed count history as feature: {conv_spk.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36688cd1",
   "metadata": {},
   "source": [
    "Letâ€™s focus on two small time windows and visualize the features, which result from convolving the counts with the basis elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e9c5c8",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the convolution results\n",
    "epoch_one_spk = nap.IntervalSet(8917.5, 8918.5)\n",
    "epoch_multi_spk = nap.IntervalSet(8979.2, 8980.2)\n",
    "\n",
    "fig = doc_plots.plot_convolved_counts(neuron_count, conv_spk, epoch_one_spk, epoch_multi_spk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca76b6",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-09.png)\n",
    ":::\n",
    "\n",
    "### Fit a GLM with basis features with reduced dimensionality\n",
    "\n",
    "\n",
    "Now that we have our \"compressed\" history feature matrix, we can fit the parameters for a new GLM model using these features.\n",
    "\n",
    "**Question: Can you fit the model using the compressed features? Call it `model_basis`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use restrict on interval set training\n",
    "model_basis = nmo.glm.GLM() # Parameter is the solver name\n",
    "model_basis.fit(\n",
    "    , # Parameter is the convolved feature matrix restricted to the first half\n",
    "     # Parameter is the binned spike count time series restricted to the first half\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc316a6f",
   "metadata": {},
   "source": [
    "(head-direction-basis-users)=\n",
    "\n",
    "We can plot the resulting response, noting that the weights we just learned needs to be \"expanded\" back\n",
    "to the original `window_size` dimension by multiplying them with the basis kernels.\n",
    "We have now 8 coefficients,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6361e6c4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "print(model_basis.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfaccd",
   "metadata": {},
   "source": [
    "In order to get the response of a neuron in response to its history, we need to multiply the coefficients by their corresponding\n",
    "basis function, and sum them.\n",
    "\n",
    "Let's do that now. We can reconstruct the history filter by multiplying the basis kernels with the learned coefficients.\n",
    "\n",
    "We can get the basis kernels by calling the `evaluate_on_grid` method of the basis object.\n",
    "\n",
    "Then we can multiply the basis kernels with the coefficients using `np.matmul`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7613b",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# get the basis function kernels\n",
    "_, basis_kernels = basis.evaluate_on_grid(window_size)\n",
    "\n",
    "# multiply with the weights\n",
    "self_connection = np.matmul(basis_kernels, model_basis.coef_)\n",
    "\n",
    "print(self_connection.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662da000",
   "metadata": {},
   "source": [
    "Let's check if our new estimate does a better job in terms of over-fitting. We can do that\n",
    "by visual comparison, as we did previously. Let's fit the second half of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8262ee3",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# fit on the other half of the data\n",
    "model_basis_second_half = nmo.glm.GLM(solver_name=\"LBFGS\").fit(\n",
    "    conv_spk.restrict(second_half), neuron_count.restrict(second_half)\n",
    ")\n",
    "self_connection_second_half = np.matmul(basis_kernels, model_basis_second_half.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c4d66",
   "metadata": {},
   "source": [
    "Let's plot the weights learned on the second half of the data and compare them to those learned on the first half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bb245",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "time = np.arange(window_size) / count.rate\n",
    "fig = plt.figure()\n",
    "plt.title(\"Spike History Weights\")\n",
    "plt.plot(time, np.squeeze(model.coef_), \"k\", alpha=0.3, label=\"GLM raw history 1st half\")\n",
    "plt.plot(time, np.squeeze(model_second_half.coef_), alpha=0.3, color=\"orange\", label=\"GLM raw history 2nd half\")\n",
    "plt.plot(time, self_connection, \"--k\", lw=2, label=\"GLM basis 1st half\")\n",
    "plt.plot(time, self_connection_second_half, color=\"orange\", lw=2, ls=\"--\", label=\"GLM basis 2nd half\")\n",
    "plt.axhline(0, color=\"k\", lw=0.5)\n",
    "plt.xlabel(\"Time from spike (sec)\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bb03a",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-10.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "Let's see if the basis model improves prediction of the firing rate. Here we will compare the firing rate predicted\n",
    "by the two models on the whole dataset. The model should be called `model` and `model_basis` from the previous cells.\n",
    "\n",
    "**Question: Can you:**\n",
    "- Predict the rates from `model` and `model_basis`? Call it `rate_history` and `rate_basis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_basis = model_basis.predict() # Parameter is the convolved feature matrix\n",
    "rate_history = model.predict() # Parameter is the original feature\n",
    "# convert the rate from spike/bin to spike/sec by multiplying with neuron_count.rate\n",
    "rate_basis = rate_basis * conv_spk.rate\n",
    "rate_history = rate_history * conv_spk.rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eaad20",
   "metadata": {},
   "source": [
    "Let's plot the predicted rates over a short window not used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35272b5e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "ep = nap.IntervalSet(start=8819.4, end=8821)\n",
    "# plot the rates\n",
    "fig = doc_plots.plot_rates_and_smoothed_counts(\n",
    "    neuron_count,\n",
    "    {\"Self-connection raw history\":rate_history, \"Self-connection basis\": rate_basis}\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13116b73",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-11.png)\n",
    ":::\n",
    "\n",
    "### All-to-all Connectivity\n",
    "\n",
    "\n",
    "The same approach can be applied to the whole population. Now the firing rate of a neuron\n",
    "is predicted not only by its own count history, but also by the rest of the\n",
    "simultaneously recorded population. We can convolve the basis with the counts of each neuron\n",
    "to get an array of predictors of shape, `(num_time_points, num_neurons * num_basis_funcs)`.\n",
    "\n",
    "\n",
    "#### Preparing the features\n",
    "\n",
    "\n",
    "**Question: Can you:**\n",
    "- Re-define the basis?\n",
    "- Convolve all counts? Call the output in `convolved_count`.\n",
    "- Print the output shape?\n",
    "\n",
    "Since this time we are convolving more than one neuron, we need to reset the expected input shape. \n",
    "This can be done by passing the population counts to the `set_input_shape` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77686805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the input shape by passing the pop. count\n",
    "print(count.shape)\n",
    "print(152/8)\n",
    "basis.set_input_shape(count)\n",
    "# convolve all the neurons\n",
    "convolved_count = basis.compute_features() # Parameter is the binned spike count time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b202a490",
   "metadata": {},
   "source": [
    "Check the dimension to make sure it make sense.\n",
    "\n",
    "Shape should be `(n_samples, n_basis_func * n_neurons)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599662b0",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Convolved count shape: {convolved_count.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba635bd",
   "metadata": {},
   "source": [
    "(head-direction-fit-users)=\n",
    "#### Fitting the Model\n",
    "\n",
    "\n",
    "This is an all-to-all neurons model.\n",
    "We are using the class [`PopulationGLM`](https://nemos.readthedocs.io/en/latest/generated/glm/nemos.glm.PopulationGLM.html) to fit the whole population at once.\n",
    "\n",
    "\n",
    "Once we condition on past activity, log-likelihood of the population is the sum of the log-likelihood\n",
    "of individual neurons. Maximizing the sum (i.e. the population log-likelihood) is equivalent to\n",
    "maximizing each individual term separately (i.e. fitting one neuron at the time).\n",
    "\n",
    "**Question: Can you:**\n",
    "- Fit a `PopulationGLM`? Call the object `model`. Solver should be `LBFGS`.\n",
    "- Use Ridge regularization with a `regularizer_strength=0.1`?\n",
    "- Print the shape of the estimated coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nmo.glm.PopulationGLM(\n",
    "    regularizer=, # Regularizer type\n",
    "    solver_name=, # Solver name\n",
    "    regularizer_strength= # Regularization strength\n",
    "    ).fit(, ) # Parameters are the convolved feature matrix and the binned spike count time series\n",
    "print(f\"Model coefficients shape: {model.coef_.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fbdd1",
   "metadata": {},
   "source": [
    "#### Comparing model predictions.\n",
    "\n",
    "\n",
    "Predict the rate (counts are already sorted by tuning prefs)\n",
    "\n",
    "**Question: Can you:**\n",
    "- Predict the firing rate of each neuron? Call it `predicted_firing_rate`.\n",
    "- Convert the rate from spike/bin to spike/sec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_firing_rate = model.predict() # Parameter is the convolved feature matrix\n",
    "# convert the rate from spike/bin to spike/sec by multiplying with conv_spk.rate\n",
    "predicted_firing_rate = predicted_firing_rate * conv_spk.rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c6ea67",
   "metadata": {},
   "source": [
    "Now we can visualize the tuning curves predicted by the model as well as the real tuning curves and the predicted firing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a13053",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# use pynapple for time axis for all variables plotted for tick labels in imshow\n",
    "fig = workshop_utils.plot_head_direction_tuning_model(tuning_curves, spikes, angle, \n",
    "                                                predicted_firing_rate, threshold_hz=1,\n",
    "                                                start=8910, end=8960, cmap_label=\"hsv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d34fad3",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-12.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "Let's see if our firing rate predictions improved and in what sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dcb6a4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = doc_plots.plot_rates_and_smoothed_counts(\n",
    "    neuron_count,\n",
    "    {\"Self-connection: raw history\": rate_history,\n",
    "     \"Self-connection: bsais\": rate_basis,\n",
    "     \"All-to-all: basis\": predicted_firing_rate[:, 0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846109dd",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-13.png)\n",
    ":::\n",
    "\n",
    "#### Visualizing the connectivity\n",
    "\n",
    "\n",
    "Finally, we can extract and visualize the pairwise interactions between neurons.\n",
    "\n",
    "**Question: Can you extract the weights and store it in a `(n_neurons, n_neurons, n_basis_funcs)` array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f95131",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# original shape of the weights\n",
    "print(f\"GLM coeff: {model.coef_.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6dac2",
   "metadata": {},
   "source": [
    "You can use the `split_by_feature` method of `basis` for this. It will reshape the coefficient vector into a 3D array.\n",
    "\n",
    "![Reshape coefficients](../../_static/coeff_reshape.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the coefficient vector along the feature axis (axis=0)\n",
    "weights_dict = basis.split_by_feature() # Parameter is the model coefficients. Axis is 0\n",
    "# The output is a dict with key the basis label, \n",
    "# and value the reshaped coefficients\n",
    "weights = weights_dict[\"RaisedCosineLogConv\"]\n",
    "print(f\"Re-shaped coefficients: {weights.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376ff03",
   "metadata": {},
   "source": [
    "The shape is `(sender_neuron, num_basis, receiver_neuron)`.\n",
    "\n",
    "Let's reconstruct the coupling filters by multiplying the weights with the basis functions. \n",
    "Here we use `np.einsum` for that. It's a powerful function for summing products of arrays over specified axes.\n",
    "In this case, the operation is :\n",
    "(sender_neuron, num_basis, receiver_neuron) x (time lag, num_basis) -> (sender_neuron, receiver_neuron, time lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef73759",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "responses = np.einsum(\"jki,tk->ijt\", weights, basis_kernels)\n",
    "\n",
    "print(responses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457c6b5",
   "metadata": {},
   "source": [
    "Finally, we can visualize the pairwise interactions by plotting\n",
    "all the coupling filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f411fb",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "predicted_tuning_curves = nap.compute_tuning_curves(\n",
    "    data=predicted_firing_rate,\n",
    "    features=angle, \n",
    "    bins=61, \n",
    "    epochs = angle.time_support,\n",
    "    range=(0, 2 * np.pi),\n",
    "    feature_names = [\"angle\"]\n",
    "    )\n",
    "\n",
    "                                                 \n",
    "fig = workshop_utils.plot_coupling_filters(responses, predicted_tuning_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7837b",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-14.png)\n",
    ":::\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "\n",
    "These coupling filters represent the influence of one neuron on another over time. \n",
    "They have been sorted based on the preferred head-direction of each neuron.\n",
    "Note that those neurons are not synaptically connected, but they have a functional relationship based on their tuning \n",
    "to head-direction."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.18.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   15,
   28,
   70,
   88,
   101,
   107,
   116,
   119,
   131,
   134,
   152,
   155,
   165,
   168,
   180,
   182,
   192,
   195,
   205,
   208,
   227,
   237,
   245,
   259,
   274,
   280,
   298,
   300,
   309,
   321,
   340,
   347,
   363,
   385,
   403,
   410,
   418,
   442,
   464,
   471,
   479,
   483,
   491,
   495,
   511,
   521,
   532,
   539,
   553,
   557,
   574,
   581,
   588,
   593,
   600,
   607,
   613,
   619,
   649,
   660,
   669,
   677,
   685,
   695,
   716,
   723,
   730,
   743,
   770,
   774,
   795,
   801,
   823,
   829,
   836,
   844,
   860,
   867,
   878,
   882,
   895,
   905,
   912,
   920,
   926,
   940,
   957,
   963,
   970,
   979,
   1008,
   1015,
   1024,
   1028,
   1048,
   1055,
   1068,
   1072,
   1079,
   1086,
   1098,
   1107,
   1122,
   1127,
   1136,
   1143,
   1155,
   1161,
   1168,
   1182
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}