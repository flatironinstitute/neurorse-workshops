{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65c88a",
   "metadata": {
    "tags": [
     "hide-input",
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"plotting functions contained within `_documentation_utils` are intended for nemos's documentation.\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Ignoring cached namespace 'core'\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=(\n",
    "        \"invalid value encountered in div \"\n",
    "    ),\n",
    "    category=RuntimeWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ef1eb",
   "metadata": {},
   "source": [
    ":::{admonition} Download\n",
    ":class: important render-all\n",
    "\n",
    "This notebook can be downloaded as **{nb-download}`place_cells-presenters.ipynb`**. See the button at the top right to download as markdown or pdf.\n",
    "\n",
    ":::\n",
    "# Model and feature selection with scikit-learn\n",
    "This notebook has had all its explanatory text removed and has not been run.\n",
    " It is intended to be downloaded and run locally (or on the provided binder)\n",
    " while listening to the presenter's explanation. In order to see the fully\n",
    " rendered of this notebook, go [here](../../full/day2/place_cells.md)\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Review how to use pynapple to analyze neuronal tuning\n",
    "- Learn how to combine NeMoS basis objects\n",
    "- Learn how to use NeMoS objects with [scikit-learn](https://scikit-learn.org/) for cross-validation\n",
    "- Learn how to use NeMoS objects with scikit-learn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- Learn how to use cross-validation to perform model and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941aa7bf",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "\n",
    "import nemos as nmo\n",
    "\n",
    "# some helper plotting functions\n",
    "from nemos import _documentation_utils as doc_plots\n",
    "import workshop_utils\n",
    "\n",
    "# configure plots some\n",
    "plt.style.use(nmo.styles.plot_style)\n",
    "\n",
    "import workshop_utils\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "\n",
    "# shut down jax to numpy conversion warning\n",
    "nap.nap_config.suppress_conversion_warnings = True\n",
    "\n",
    "# during development, set this to a lower number so everything runs faster. \n",
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c880d2",
   "metadata": {},
   "source": [
    "## Pynapple\n",
    "\n",
    "- Load the data using pynapple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372256f",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "path = workshop_utils.fetch_data(\"Achilles_10252013_EEG.nwb\")\n",
    "data = nap.load_file(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4874cee",
   "metadata": {},
   "source": [
    "- Extract the spike times and mouse position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402b7f5",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = data[\"units\"]\n",
    "position = data[\"position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b44723",
   "metadata": {},
   "source": [
    "- Restrict data to when animal was traversing the linear track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe410e51",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "position = position.restrict(data[\"forward_ep\"])\n",
    "spikes = spikes.restrict(data[\"forward_ep\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9107d",
   "metadata": {},
   "source": [
    "- Restrict neurons to only excitatory neurons, discarding neurons with a low-firing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80778e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "spikes = spikes.getby_category(\"cell_type\")[\"pE\"]\n",
    "spikes = spikes.getby_threshold(\"rate\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df883936",
   "metadata": {},
   "source": [
    "### Place fields\n",
    "\n",
    "\n",
    "- Visualize the *place fields*: neuronal firing rate as a function of position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637dd2ce",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "place_fields = nap.compute_1d_tuning_curves(spikes, position, 50, position.time_support)\n",
    "workshop_utils.plot_place_fields(place_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68736f0d",
   "metadata": {},
   "source": [
    "- For speed, we're only going to investigate the three neurons highlighted above.\n",
    "- Bin spikes to counts at 100 Hz.\n",
    "- Interpolate position to match spike resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf9a6b",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "neurons = [82, 92, 220]\n",
    "place_fields = place_fields[neurons]\n",
    "spikes = spikes[neurons]\n",
    "bin_size = .01\n",
    "count = spikes.count(bin_size, ep=position.time_support)\n",
    "position = position.interpolate(count, ep=count.time_support)\n",
    "print(count.shape)\n",
    "print(position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed89d4",
   "metadata": {},
   "source": [
    "### Speed modulation\n",
    "\n",
    "\n",
    "- Compute animal's speed for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68690c61",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "speed = []\n",
    "# Analyzing each epoch separately avoids edge effects.\n",
    "for s, e in position.time_support.values: \n",
    "    pos_ep = position.get(s, e)\n",
    "    # Absolute difference of two consecutive points\n",
    "    speed_ep = np.abs(np.diff(pos_ep)) \n",
    "    # Padding the edge so that the size is the same as the position/spike counts\n",
    "    speed_ep = np.pad(speed_ep, [0, 1], mode=\"edge\") \n",
    "    # Converting to cm/s \n",
    "    speed_ep = speed_ep * position.rate\n",
    "    speed.append(speed_ep)\n",
    "\n",
    "speed = nap.Tsd(t=position.t, d=np.hstack(speed), time_support=position.time_support)\n",
    "print(speed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb8907",
   "metadata": {},
   "source": [
    "- Compute the tuning curve with pynapple's [`compute_1d_tuning_curves`](https://pynapple.org/generated/pynapple.process.tuning_curves.html#pynapple.process.tuning_curves.compute_1d_tuning_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_speed = nap.compute_1d_tuning_curves(spikes, speed, 20, speed.time_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d16df",
   "metadata": {},
   "source": [
    "- Visualize the position and speed tuning for these neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83886ddf",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = workshop_utils.plot_position_speed(position, speed, place_fields, tc_speed, neurons);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2cd03",
   "metadata": {},
   "source": [
    "These neurons all show both position and speed tuning, and we see that the animal's speed and position are highly correlated. We're going to build a GLM to predict neuronal firing rate -- which variable should we use? Is the speed tuning just epiphenomenal?\n",
    "\n",
    "\n",
    "## NeMoS\n",
    "### Basis evaluation\n",
    "\n",
    "\n",
    "- why basis?\n",
    "   - without basis:\n",
    "     - either the GLM says that firing rate increases exponentially as position or speed increases, which is fairly nonsensical,\n",
    "     - or we have to fit the weight separately for each position or speed, which is really high-dim\n",
    "   - so, basis allows us to reduce dimensionality, capture non-linear modulation of firing rate (in this case, tuning)\n",
    "- why eval?\n",
    "    - basis objects have two modes:\n",
    "    - conv, like we've seen, for capturing time-dependent effects\n",
    "    - eval, for capturing non-linear modulation / tuning\n",
    "- why MSpline?\n",
    "    - when deciding on eval basis, look at the tuning you want to capture, compare to the kernels: you want your tuning to be capturable by a linear combination of these\n",
    "    - in cases like this, many possible basis objects we could use here and what I'll show you in a bit will allow you to determine which to use in principled manner\n",
    "    - MSpline, BSpline, RaisedCosineLinear : all would let you capture this\n",
    "    - weird choices:\n",
    "        - cyclic bspline, except maybe for position? if end and start are the same\n",
    "        - RaisedCosineLog (don't want the stretching)\n",
    "        - orthogonalized exponential (specialized for...)\n",
    "        - identity / history (too basic)\n",
    "\n",
    "\n",
    "\n",
    "- Create a separate basis object for each model input.\n",
    "- Visualize the basis objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10)\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15)\n",
    "workshop_utils.plot_pos_speed_bases(position_basis, speed_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63370c0c",
   "metadata": {},
   "source": [
    "- Combine the two basis objects into a single \"additive basis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e066e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to calling nmo.basis.AdditiveBasis(position_basis, speed_basis)\n",
    "basis = position_basis + speed_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7b3c6",
   "metadata": {},
   "source": [
    "- Create the design matrix!\n",
    "- Notice that, since we passed the basis pynapple objects, we got one back, preserving the time stamps.\n",
    "- `X` has the same number of time points as our input position and speed, but 25 columns. The columns come from  `n_basis_funcs` from each basis (10 for position, 15 for speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27849b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = basis.compute_features(position, speed)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9278e",
   "metadata": {},
   "source": [
    "### Model learning\n",
    "\n",
    "\n",
    "- Initialize `PopulationGLM`\n",
    "- Use the \"LBFGS\" solver and pass `{\"tol\": 1e-12}` to `solver_kwargs`.\n",
    "- Fit the data, passing the design matrix and spike counts to the glm object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = nmo.glm.PopulationGLM(\n",
    "    solver_kwargs={\"tol\": 1e-12},\n",
    "    solver_name=\"LBFGS\",\n",
    ")\n",
    "\n",
    "glm.fit(X, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e25ed",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "\n",
    "- Use `predict` to check whether our GLM has captured each neuron's speed and position tuning.\n",
    "- Remember to convert the predicted firing rate to spikes per second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model's firing rate\n",
    "predicted_rate = glm.predict(X) / bin_size\n",
    "\n",
    "# same shape as the counts we were trying to predict\n",
    "print(predicted_rate.shape, count.shape)\n",
    "\n",
    "# compute the position and speed tuning curves using the predicted firing rate.\n",
    "glm_pos = nap.compute_1d_tuning_curves_continuous(predicted_rate, position, 50, position.time_support)\n",
    "glm_speed = nap.compute_1d_tuning_curves_continuous(predicted_rate, speed, 30, speed.time_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2816d6",
   "metadata": {},
   "source": [
    "- Compare model and data tuning curves together. The model did a pretty good job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43315cd",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "workshop_utils.plot_position_speed_tuning(place_fields, tc_speed, glm_pos, glm_speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85248858",
   "metadata": {},
   "source": [
    "We can see that this model does a good job capturing both the position and the speed. In the rest of this notebook, we're going to investigate all the scientific decisions that we swept under the rug: should we regularize the model? what basis should we use? do we need both inputs?\n",
    "\n",
    "To make our lives easier, let's create a helper function that wraps the above\n",
    "lines, because we're going to be visualizing our model predictions a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5487766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_predictions(glm, X):\n",
    "    # predict the model's firing rate\n",
    "    predicted_rate = glm.predict(X) / bin_size\n",
    "\n",
    "    # compute the position and speed tuning curves using the predicted firing rate.\n",
    "    glm_pos = nap.compute_1d_tuning_curves_continuous(predicted_rate, position, 50, position.time_support)\n",
    "    glm_speed = nap.compute_1d_tuning_curves_continuous(predicted_rate, speed, 30, position.time_support)\n",
    "\n",
    "    workshop_utils.plot_position_speed_tuning(place_fields, tc_speed, glm_pos, glm_speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394eda1f",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "### How to know when to regularize?\n",
    "\n",
    "\n",
    "- How do we decide when to use regularization?\n",
    "- Cross-validation allows you to fairly compare different models on the same dataset.\n",
    "- NeMoS makes use of [scikit-learn](https://scikit-learn.org/), the standard machine learning library in python.\n",
    "- Define [parameter grid](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) to search over.\n",
    "- Anything not specified in grid will be kept constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regularizer\": [\"UnRegularized\", \"Ridge\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5be14",
   "metadata": {},
   "source": [
    "- Initialize scikit-learn's [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833816a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.GridSearchCV(glm, param_grid, cv=cv_folds)\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f4f2a",
   "metadata": {},
   "source": [
    "- We interact with this in a very similar way to the glm object.\n",
    "- In particular, call `fit` with same arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaddd5c4",
   "metadata": {},
   "source": [
    "- We got a warning because we didn't specify the regularizer strength, so we just fell back on default value.\n",
    "- Let's investigate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26a943",
   "metadata": {},
   "source": [
    "<div class=\"render-all\">\n",
    "\n",
    ":::{note}\n",
    "You could (and generally, should!) investigate `regularizer_strength`, but we're skipping for simplicity. To do this properly, use a slightly different syntax for `param_grid` (list of dictionaries, instead of single dictionary)\n",
    "\n",
    "```python\n",
    "param_grid = [\n",
    "    {\"regularizer\": [nmo.regularizer.UnRegularized()]},\n",
    "    {\"regularizer\": [nmo.regularizer.Ridge()],\n",
    "     \"regularizer_strength\": [1e-6, 1e-3, 1]}\n",
    "]\n",
    "```\n",
    ":::\n",
    "\n",
    "</div>\n",
    "### Select basis\n",
    "\n",
    "\n",
    "- You can (and should) do something similar to determine how many basis functions you need for each input.\n",
    "- NeMoS basis objects are not scikit-learn-compatible right out of the box.\n",
    "- But we have provided a simple method to make them so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10).to_transformer()\n",
    "# or equivalently:\n",
    "position_basis = nmo.basis.TransformerBasis(nmo.basis.MSplineEval(n_basis_funcs=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193a69d",
   "metadata": {},
   "source": [
    "- This gives the basis object the `transform` method, which is equivalent to `compute_features`.\n",
    "- However, transformers have some limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a8c9d",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "position_basis.transform(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14f8357",
   "metadata": {},
   "source": [
    "- Transformers only accept 2d inputs, whereas nemos basis objects can accept inputs of any dimensionality.\n",
    "- In order to tell nemos how to reshape the 2d matrix that is the input of `transform` to whatever the basis accepts, you need to call `set_input_shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can accept array\n",
    "position_basis.set_input_shape(position)\n",
    "# int\n",
    "position_basis.set_input_shape(1)\n",
    "# tuple\n",
    "position_basis.set_input_shape(position.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d73e27",
   "metadata": {},
   "source": [
    "- Then you can call transform on the 2d input as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input needs to be 2d, so use expand_dims\n",
    "position_basis.transform(np.expand_dims(position, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207da9c",
   "metadata": {},
   "source": [
    "- You can, equivalently, call `compute_features` *before* turning the basis into a transformer. Then we cache the shape for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76041ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_basis = nmo.basis.MSplineEval(n_basis_funcs=10)\n",
    "position_basis.compute_features(position)\n",
    "position_basis = position_basis.to_transformer()\n",
    "speed_basis = nmo.basis.MSplineEval(n_basis_funcs=15).to_transformer().set_input_shape(1)\n",
    "basis = position_basis + speed_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f68cd",
   "metadata": {},
   "source": [
    "- Create a single TsdFrame to hold all our inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70fef4",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "transformer_input = nap.TsdFrame(\n",
    "    t=position.t,\n",
    "    d=np.stack([position.d, speed.d], 1),\n",
    "    time_support=position.time_support,\n",
    "    columns=[\"position\", \"speed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc02331",
   "metadata": {},
   "source": [
    "- Pass this input to our transformed additive basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis.transform(transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2731b4d",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "\n",
    "- If we want to cross-validate over the basis, we need more one more step: combining the basis and the GLM into a single scikit-learn estimator.\n",
    "- [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c23303",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline.Pipeline([\n",
    "    (\"basis\", basis),\n",
    "    (\"glm\", glm)\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b8d82",
   "metadata": {},
   "source": [
    "- Pipeline runs `basis.transform`, then passes that output to `glm`, so we can do everything in a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeae9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018edf37",
   "metadata": {},
   "source": [
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a367a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model_predictions(pipe, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7494c3",
   "metadata": {},
   "source": [
    "### Cross-validating on the basis\n",
    "\n",
    "\n",
    "Now that we have our pipeline estimator, we can cross-validate on any of its parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d941a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffaf132",
   "metadata": {},
   "source": [
    "Let's cross-validate on:\n",
    "- The number of the basis functions of the position basis\n",
    "- The functional form of the basis for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f68f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipe[\"basis\"].basis1.n_basis_funcs)\n",
    "print(pipe[\"basis\"].basis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ac6d9",
   "metadata": {},
   "source": [
    "- Construct `param_grid`, using `__` to stand in for `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"basis__basis1__n_basis_funcs\": [5, 10, 20],\n",
    "    \"basis__basis2\": [nmo.basis.MSplineEval(15).set_input_shape(1),\n",
    "                      nmo.basis.BSplineEval(15).set_input_shape(1),\n",
    "                      nmo.basis.RaisedCosineLinearEval(15).set_input_shape(1)],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cde66e",
   "metadata": {},
   "source": [
    "- Cross-validate as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.GridSearchCV(pipe, param_grid, cv=cv_folds)\n",
    "cv.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ab4ac",
   "metadata": {},
   "source": [
    "- Investigate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6d2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3445e",
   "metadata": {},
   "source": [
    "- These results are more complicated, so let's use [pandas dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) to make them a bit more understandable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(cv.cv_results_)\n",
    "cv_df\n",
    "# helper function for visualization\n",
    "workshop_utils.plot_heatmap_cv_results(cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b40aed",
   "metadata": {},
   "source": [
    "- Can easily grab the best estimator, the pipeline that did the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf688b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estim = cv.best_estimator_\n",
    "best_estim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e8cae",
   "metadata": {},
   "source": [
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da0375e",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(best_estim, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f3cbc",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "\n",
    "- Now one more thing we can do with scikit-learn!\n",
    "- Each `PopulationGLM` object has a feature mask, which allows us to exclude certain parts of the input\n",
    "- Feature mask shape: `X.shape[1]` (number of columns in the design matrix) by `n_neurons` (number of neurons we're trying to predict)\n",
    "- (By default, everything is included.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe['glm'].feature_mask\n",
    "print(pipe['glm'].feature_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_utils.plot_feature_mask(pipe[\"glm\"].feature_mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624ce3b",
   "metadata": {},
   "source": [
    "- We could manually edit feature mask, but have some helper functions -- these are currently being developed, so any feedback is appreciated!\n",
    "- By default, we include all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = workshop_utils.create_feature_mask(pipe[\"basis\"], n_neurons=count.shape[1])\n",
    "workshop_utils.plot_feature_mask(m);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29ecf0",
   "metadata": {},
   "source": [
    "- Make use of our additive basis to figure out the structure in the input\n",
    "- Can selectively remove some of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8082be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = workshop_utils.create_feature_mask(pipe[\"basis\"], [\"all\", \"none\"], n_neurons=count.shape[1])\n",
    "fig=workshop_utils.plot_feature_mask(m);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa02abb",
   "metadata": {},
   "source": [
    "- Can construct a set of feature masks that includes / excludes each of the sets of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484432db",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_masks = [\n",
    "    workshop_utils.create_feature_mask(basis, \"all\", n_neurons=count.shape[1]),\n",
    "    workshop_utils.create_feature_mask(basis, [\"all\", \"none\"], n_neurons=count.shape[1]),\n",
    "    workshop_utils.create_feature_mask(basis, [\"none\", \"all\"], n_neurons=count.shape[1]),\n",
    "]\n",
    "\n",
    "workshop_utils.plot_feature_mask(feature_masks, [\"All\", \"Position\", \"Speed\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd349c03",
   "metadata": {},
   "source": [
    "- One more wrinkle: the shape of this feature mask depends on the number of basis functions!\n",
    "- Thus, must create a new feature mask for each possible arrangement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099efd31",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "param_grid = workshop_utils.create_feature_mask_paramgrid(basis, [5, 10, 20], \n",
    "                                                          [8, 16, 32], count.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca08de",
   "metadata": {},
   "source": [
    "- Initialize and fit GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8293ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = model_selection.GridSearchCV(best_estim, param_grid, cv=cv_folds)\n",
    "cv.fit(transformer_input, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fd74c",
   "metadata": {},
   "source": [
    "- Investigate results using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205ca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(cv.cv_results_)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97445398",
   "metadata": {},
   "source": [
    "- For our own sanity, let's create an easier-to-read label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df95c6d",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# create a custom label to make the results easier to parse\n",
    "def label_feature_mask(x):\n",
    "    mask = x.param_glm__feature_mask\n",
    "    if mask.sum() / np.prod(mask.shape) == 1:\n",
    "        return \"all\"\n",
    "    elif mask[0,0] == 1:\n",
    "        return \"position\"\n",
    "    else:\n",
    "        return \"speed\"\n",
    "\n",
    "cv_df['feature_mask_label'] = cv_df.apply(label_feature_mask, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eece5a",
   "metadata": {},
   "source": [
    "- And visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ad1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_utils.plot_heatmap_cv_results(cv_df, \"feature_mask_label\", columns=\"param_basis__basis2__n_basis_funcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baf2ce",
   "metadata": {},
   "source": [
    "From the above plots, we can see that:\n",
    "- Position matters more than speed.\n",
    "- Number of basis functions for speed doesn't matter much.\n",
    "- We don't need many basis functions to represent the position.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Visualize model predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977781be",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "visualize_model_predictions(cv.best_estimator_, transformer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a283d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "## References\n",
    "\n",
    "\n",
    "The data in this tutorial comes from [Grosmark, Andres D., and György Buzsáki. \"Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences.\" Science 351.6280 (2016): 1440-1443](https://www.science.org/doi/full/10.1126/science.aad1935)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   13,
   41,
   64,
   91,
   96,
   102,
   106,
   111,
   117,
   122,
   128,
   133,
   139,
   144,
   152,
   163,
   170,
   187,
   193,
   195,
   200,
   204,
   238,
   242,
   247,
   250,
   258,
   261,
   270,
   277,
   285,
   295,
   301,
   305,
   314,
   324,
   336,
   340,
   345,
   348,
   354,
   356,
   362,
   364,
   388,
   392,
   399,
   403,
   410,
   417,
   422,
   425,
   431,
   437,
   442,
   451,
   456,
   458,
   466,
   472,
   477,
   479,
   485,
   487,
   494,
   496,
   503,
   506,
   511,
   518,
   523,
   526,
   531,
   533,
   538,
   543,
   548,
   551,
   557,
   560,
   569,
   573,
   575,
   581,
   584,
   590,
   593,
   598,
   606,
   612,
   617,
   622,
   625,
   630,
   633,
   638,
   652,
   657,
   659,
   673,
   676
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}