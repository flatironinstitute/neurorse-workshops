{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e08d67f",
   "metadata": {
    "tags": [
     "hide-input",
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"plotting functions contained within `_documentation_utils` are intended for nemos's documentation.\",\n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c5945",
   "metadata": {},
   "source": [
    ":::{admonition} Download\n",
    ":class: important render-all\n",
    "\n",
    "This notebook can be downloaded as **{nb-download}`03_calcium_imaging_analysis-users.ipynb`**. See the button at the top right to download as markdown or pdf.\n",
    ":::\n",
    "# Calcium imaging analysis of head-direction cells\n",
    "This notebook has had all its explanatory text removed and has not been run.\n",
    " It is intended to be downloaded and run locally (or on the provided binder),\n",
    " working through the questions with your small group.\n",
    "## Part 1 : Analyzing calcium imaging with pynapple\n",
    "\n",
    "\n",
    "For this part of the group project, we will use pynapple to do the following tasks:\n",
    "1. Loading a NWB file\n",
    "2. Compute tuning curves\n",
    "3. Visualize tuning curves\n",
    "4. Decode head-direction from neural activity\n",
    "\n",
    "\n",
    "Let's start by importing the necessary libraries and fetching the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eeb77c",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "import workshop_utils\n",
    "import pynapple as nap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nemos as nmo\n",
    "\n",
    "# some helper plotting functions\n",
    "from nemos import _documentation_utils as doc_plots\n",
    "\n",
    "# configure pynapple to ignore conversion warning\n",
    "nap.nap_config.suppress_conversion_warnings = True\n",
    "\n",
    "# configure plot style\n",
    "plt.style.use(nmo.styles.plot_style)\n",
    "\n",
    "# fetch data\n",
    "path = workshop_utils.fetch_data(\"A0670-221213.nwb\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b96e0",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "\n",
    "Similar to part 1, we will start by loading the NWB file. The function `nap.load_file` can be used again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ... # Load NWB file\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5edeb",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "data = nap.load_file(path)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51be664",
   "metadata": {},
   "source": [
    "There are multiple entries in the NWB file. The calcium transients are stored in the `RoiResponseSeries` entry.\n",
    "The head-direction of the animal is stored in the `ry` entry. Let's extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b518867",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "transients = data[\"RoiResponseSeries\"]\n",
    "angle = data[\"ry\"]\n",
    "print(transients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b064ec27",
   "metadata": {},
   "source": [
    "To get an idea of the data, let's visualize the calcium transients of the first two neurons for the first 100 seconds of the recording.\n",
    "Instead of creating a new `IntervalSet` object, we can use the method `transients.get(0, 100)` to get a restricted version of the `Tsd` object.\n",
    "Contrary to `restrict`, which takes an `IntervalSet` object as input, `get` can take start and end times directly as input and does not \n",
    "update the time support of the output `Tsd` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32725592",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(transients[:,0:2].get(0, 100))\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Fluorescence (a.u.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7eb96",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-04.png)\n",
    ":::\n",
    "\n",
    "### Compute tuning curves\n",
    "\n",
    "\n",
    "Now we have \n",
    "- calcium transients\n",
    "- a behavioral feature (i.e. head-direction),\n",
    "We can compute tuning curves, i.e. the fluorescence of neurons as a function of head-direction. \n",
    "We want to know how the fluorescence of each neuron changes as a function of the head-direction of the animal.\n",
    "We can use the same function as before : `nap.compute_tuning_curves`. \n",
    "Don't forget to give a name to the feature when calling the function (i.e. `feature_names = [\"angle\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_curves = nap.compute_tuning_curves(\n",
    "    data=, # The neural activity as a TsGroup\n",
    "    features=, # Which feature? Here the head-direction of the animal\n",
    "    bins=, # How many bins of feature space? Here 61 angular bins is a good numbers \n",
    "    range=, # The min and max of the bin array\n",
    "    feature_names =  # Let's give a name to our feature for better labelling of the output.\n",
    "    ) \n",
    "tuning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9e2de",
   "metadata": {},
   "source": [
    "### Visualize tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc73482",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.subplot(221)\n",
    "tuning_curves[0].plot()\n",
    "plt.subplot(222,projection='polar')\n",
    "plt.plot(tuning_curves.angle, tuning_curves[0].values)\n",
    "plt.subplot(223)\n",
    "tuning_curves[1].plot()\n",
    "plt.subplot(224,projection='polar')\n",
    "plt.plot(tuning_curves.angle, tuning_curves[1].values)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95158b2b",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-05.png)\n",
    ":::\n",
    "\n",
    "### Decode head-direction from neural activity\n",
    "\n",
    "\n",
    "Now that we have the tuning curves, we can use them to decode the head-direction of the animal from the neural activity.\n",
    "Pynapple provides two functions to do this: `nap.decode_bayes` for spike counts and `nap.decode_template` for event rates or continuous data. \n",
    "Since the data are calcium transients and not spike counts, we will use the template matching method.\n",
    "\n",
    "**Question:** Can you decode the head-direction of the animal using the function `nap.decode_template` and call the variable `decoded_angle`?\n",
    "\n",
    "We will us the epoch `epochs = nap.IntervalSet([50, 150])` to restrict the decoding to the first 100 seconds of the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea068aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = nap.IntervalSet(start=50, end=150)\n",
    "decoded_angle, dist = nap.decode_template(\n",
    "    tuning_curves=..., # The tuning curves as an xarray object\n",
    "    data=..., # The neural activity as a TsdFrame in this case\n",
    "    bin_size=..., # The bin size for decoding. Here I suggest 0.1 second\n",
    "    metric=... # The metric to use to compare the neural activity to the tuning curves. Here I suggest \"correlation\"\n",
    "    epochs=transients.time_support # The epochs should correspond to when the neural activity is defined. Here we use the time support directly\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533bcdf",
   "metadata": {},
   "source": [
    "Let's visualize the decoded head-direction of the animal for the first 100 seconds of the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c011f9",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(figsize=(8, 8), nrows=2, ncols=1, sharex=True)\n",
    "ax1.plot(angle.restrict(epochs), label=\"True\")\n",
    "ax1.scatter(decoded_angle.times(), decoded_angle.values, label=\"Decoded\", c=\"orange\")\n",
    "ax1.legend(frameon=False, bbox_to_anchor=(1.0, 1.0))\n",
    "ax1.set_ylabel(\"Angle [rad]\")\n",
    "\n",
    "im = ax2.imshow(\n",
    "    dist.values.T, \n",
    "    aspect=\"auto\", \n",
    "    origin=\"lower\", \n",
    "    cmap=\"inferno_r\", \n",
    "    extent=(epochs.start[0], epochs.end[0], 0.0, 2*np.pi)\n",
    ")\n",
    "ax2.set_ylabel(\"Angle [rad]\")\n",
    "cbar_ax2 = fig.add_axes([0.95, ax2.get_position().y0, 0.015, ax2.get_position().height])\n",
    "fig.colorbar(im, cax=cbar_ax2, label=\"Distance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b138b57",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/01-06.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "The first panel shows the true head-direction of the animal and the decoded head-direction from neural activity.\n",
    "The second panel shows the distance between the neural activity and the tuning curves as a function of time and angle.\n",
    "\n",
    "You can play with the metric parameters of the decoding function to see how it affects the decoding performance. \n",
    "Possible metrics are \"euclidean\", \"manhattan\", \"correlation\", \"jensenshannon\" and \"cosine\". \n",
    "\n",
    "\n",
    "## Part 2 : Modelling calcium imaging data with GLM\n",
    "### Preprocessing the data\n",
    "\n",
    "\n",
    "To speed up the analysis, the following code computes a Rayleigh test to select only neurons that are significantly tuned to head-direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d2e70",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "C = np.sum(tuning_curves.values * np.cos(tuning_curves.angle.values), axis=1) / np.sum(tuning_curves.values, axis=1)\n",
    "S = np.sum(tuning_curves.values * np.sin(tuning_curves.angle.values), axis=1) / np.sum(tuning_curves.values, axis=1)\n",
    "R = np.sqrt(C**2 + S**2)\n",
    "Z = tuning_curves.shape[1] * R**2\n",
    "p_value = np.exp(-Z)\n",
    "\n",
    "tokeep_neurons = np.where(p_value < 0.01)[0]\n",
    "transients = transients[:, tokeep_neurons]\n",
    "tuning_curves = tuning_curves[tokeep_neurons]\n",
    "print(f\"Number of neurons after tuning selection: {transients.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66da6d",
   "metadata": {},
   "source": [
    "Finally, we sort the neurons based on their preferred head-direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4d5eb",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "pref_ang = tuning_curves.idxmax(dim=\"angle\")\n",
    "sort_idx = np.argsort(pref_ang.values)\n",
    "transients = transients[:, sort_idx]\n",
    "tuning_curves = tuning_curves[sort_idx]\n",
    "pref_ang = pref_ang[sort_idx]\n",
    "transients.set_info(pref_ang=pref_ang)\n",
    "print(transients) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec637c8",
   "metadata": {},
   "source": [
    "### Basis functions for calcium data\n",
    "\n",
    "\n",
    "Here we can use the same `RaisedCosineLogConv` basis, but with a larger window size to capture the slower dynamics of calcium signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ecc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the basis for calcium data\n",
    "calcium_window_size_sec = 2 # Window size in seconds\n",
    "calcium_window_size = int(calcium_window_size_sec * transients.rate) # Convert window size to number of bins\n",
    "calcium_basis = nmo.basis.RaisedCosineLogConv(\n",
    "    n_basis_funcs=..., # Number of basis functions \n",
    "    window_size=calcium_window_size # Window size in bins\n",
    ")\n",
    "calcium_basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80bc4d",
   "metadata": {},
   "source": [
    "### Preparing the features\n",
    "\n",
    "We can convolve the calcium transients with the basis functions to get the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve all the neurons\n",
    "calcium_convolved = calcium_basis.compute_features( ) # Parameter is the calcium transients\n",
    "print(f\"Convolved calcium shape: {calcium_convolved.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51933c02",
   "metadata": {},
   "source": [
    "### Fitting the Population GLM\n",
    "\n",
    "We can fit a `PopulationGLM` to the calcium data using a Gamma observation model, which is more appropriate for continuous-valued data.\n",
    "\n",
    "Similar to before, we will create a train-test split using the first and second half of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed9628",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "duration = calcium_convolved.time_support.tot_length(\"s\")\n",
    "start = calcium_convolved.time_support[\"start\"]\n",
    "end = calcium_convolved.time_support[\"end\"]\n",
    "training_ep = nap.IntervalSet(start, start + duration / 2)\n",
    "testing_ep = nap.IntervalSet(start + duration / 2, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eacf50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcium_model = nmo.glm.PopulationGLM(\n",
    "    observation_model=..., # Observation model type\n",
    "    regularizer=..., # Regularizer type\n",
    "    solver_name=..., # Solver name\n",
    "    regularizer_strength=... # Regularization strength\n",
    "    ).fit( , ) # Parameters are the convolved feature matrix and the calcium transients during training epoch\n",
    "print(f\"Calcium model coefficients shape: {calcium_model.coef_.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f454a",
   "metadata": {},
   "source": [
    "### Predicting and visualizing the results\n",
    "\n",
    "We can predict the calcium signals using the fitted model during the test epoch and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f878eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcium_predicted = calcium_model.predict( ) # Parameter is the convolved feature matrix restricted during testing epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5760ca2",
   "metadata": {},
   "source": [
    "We can visualize the predicted calcium signals alongside the actual signals to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e39edc",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "ep_to_plot = nap.IntervalSet(testing_ep.start[0], testing_ep.start[0] + 100)  # Plot first 10 seconds of test epoch\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(transients.restrict(ep_to_plot)[:,0], label=\"Actual Calcium\")\n",
    "plt.plot(calcium_predicted.restrict(ep_to_plot)[:,0], label=\"Predicted Calcium\")\n",
    "plt.legend()\n",
    "plt.title(\"Calcium Signal Prediction\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Fluorescence Intensity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1abf79",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/02-12.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "Similar to the spike data, we can extract and visualize the coupling filters between neurons based on the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09243882",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "# split the coefficient vector along the feature axis (axis=0)\n",
    "calcium_weights_dict = calcium_basis.split_by_feature(calcium_model.coef_, axis=0)\n",
    "# The output is a dict with key the basis label, \n",
    "# and value the reshaped coefficients\n",
    "calcium_weights = calcium_weights_dict[\"RaisedCosineLogConv\"]\n",
    "# reconstruct the coupling filters\n",
    "time, basis_kernels = calcium_basis.evaluate_on_grid(calcium_window_size)\n",
    "calcium_responses = np.einsum(\"jki,tk->ijt\", calcium_weights, basis_kernels)\n",
    "print(calcium_responses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff38f8b",
   "metadata": {
    "tags": [
     "render-all"
    ]
   },
   "outputs": [],
   "source": [
    "fig = workshop_utils.plot_coupling_filters(calcium_responses, tuning_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8267487",
   "metadata": {},
   "source": [
    ":::{admonition} Figure check\n",
    ":class: dropdown\n",
    "![](../../_static/_check_figs/02-13.png)\n",
    ":::\n",
    "\n",
    "\n",
    "\n",
    "These coupling filters represent the functional relationships between neurons based on their calcium signal.\n",
    "Note that the slower dynamics of calcium signals may lead to different coupling patterns compared to spike data.\n",
    "\n",
    "The end of this group project. You can explore further by trying different basis functions, regularization strengths, or observation models.\n",
    "You can also try to incorporate external covariates, such as the head-direction signal, into the model.\n",
    "You can try to downsample the data to see how it affects the model fitting and predictions (i.e. check `bin_average` in pynapple to downsample the transients)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.18.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   15,
   28,
   50,
   71,
   79,
   84,
   89,
   96,
   101,
   110,
   116,
   136,
   145,
   148,
   161,
   181,
   190,
   195,
   215,
   238,
   250,
   256,
   265,
   273,
   282,
   289,
   293,
   302,
   311,
   319,
   326,
   328,
   333,
   344,
   355,
   367,
   370
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}